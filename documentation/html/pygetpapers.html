<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>pygetpapers.pygetpapers API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pygetpapers.pygetpapers</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from pygetpapers.download_tools import download_tools
from pygetpapers.europe_pmc import europe_pmc


class pygetpapers(download_tools):

    def __init__(self):
        &#34;&#34;&#34;
        This function makes all the constants
        &#34;&#34;&#34;
        import os
        self.LOGGING_URL = os.path.join(str(os.getcwd()), &#39;*&#39;, &#39;fulltext.xml&#39;)
        self.EUPMCJSON = os.path.join(str(os.getcwd()), &#39;eupmc_results.json&#39;)
        self.EUPMCCSVURL = os.path.join(str(os.getcwd()), &#39;europe_pmc.csv&#39;)
        self.TITLE = &#34;title&#34;
        self.AUTHORINFO = &#34;authorinfo&#34;
        self.JOURNALTITLE = &#34;journaltitle&#34;
        self.PDFLINKS = &#34;pdflinks&#34;
        self.HTMLLINKS = &#34;htmllinks&#34;
        self.PMCID = &#34;pmcid&#34;
        self.RESPONSE_WRAPPER = &#34;responseWrapper&#34;
        self.CURSOR_MARK = &#34;nextCursorMark&#34;
        self.europe_pmc = europe_pmc()
        self.directory_url = os.path.join(
            str(os.getcwd()))

    def make_initial_columns_for_paper_dict(self, pmcid, resultant_dict):
        &#34;&#34;&#34;
        :param pmcid: pmcid of the paper for which fields will be created
        :param resultant_dict: dict in which the fields will be created
        :return: dict with the initial fields created for pmcid
        &#34;&#34;&#34;
        resultant_dict[pmcid] = {}
        resultant_dict[pmcid][&#34;downloaded&#34;] = False
        resultant_dict[pmcid][&#34;pdfdownloaded&#34;] = False
        resultant_dict[pmcid][&#34;jsondownloaded&#34;] = False
        resultant_dict[pmcid][&#34;csvmade&#34;] = False
        return resultant_dict
    # this is the function that will the the result from search and will download and save the files.

    def makecsv(self, searchvariable, makecsv=False, update=False):
        &#34;&#34;&#34;
        Writes the json and *csv for searchvaraible dict

        :param searchvariable(dict): Python dictionary which contains all the research papers (given by europe_pmc.europepmc))

        :param makecsv(bool): whether to make csv files

        :param update(dict): if provided, will add the research papers to the searchvariable dict

        :return: searchvariable
        &#34;&#34;&#34;
        import pandas as pd
        import json
        import os
        import logging
        resultant_dict = {}
        for paper_number, papers in enumerate(searchvariable):
            output_dict = json.loads(json.dumps(papers))
            for paper in output_dict:
                if self.PMCID in paper:
                    paper_number += 1
                    htmlurl, paperpmcid, pdfurl, resultant_dict = self.write_meta_data_for_paper(
                        paper, paper_number, resultant_dict)
                    self.add_fields_to_resultant_dict(
                        htmlurl, paper, paper_number, pdfurl, resultant_dict[paperpmcid])
                    logging.debug(
                        f&#39;Wrote Meta Data to a dictionary that will be written to all the chosen metadata file formats for paper {paperpmcid}&#39;)
        if update:
            resultant_dict.update(update)
        directory_url = os.path.join(
            str(os.getcwd()))
        jsonurl = os.path.join(
            str(os.getcwd()), &#39;eupmc_results.json&#39;)
        super().check_or_make_directory(directory_url)
        self.makejson(jsonurl, resultant_dict)
        resultant_dict_for_csv = super().make_dict_for_csv(resultant_dict)
        df = pd.DataFrame.from_dict(resultant_dict_for_csv, )
        df_transposed = df.T
        if makecsv:
            super().write_or_append_to_csv(df_transposed)
        return searchvariable

    def write_meta_data_for_paper(self, paper, paper_number, resultant_dict):
        &#34;&#34;&#34;
        Adds pdf and html url as well as makes the paper key in resultant_dict

        :param paper: python dictionary for the paper

        :param paper_number: paper number to log

        :param resultant_dict: dictionary to add paper as well as pdf,html url to

        :return: (htmlurl, paperpmcid, pdfurl, resultant_dict)
        &#34;&#34;&#34;
        import logging
        logging.debug(
            f&#34;Reading Query Result for paper {paper_number}&#34;)
        pdfurl = []
        htmlurl = []
        for x in paper[&#34;fullTextUrlList&#34;][&#34;fullTextUrl&#34;]:
            if x[&#34;documentStyle&#34;] == &#34;pdf&#34; and x[&#34;availability&#34;] == &#34;Open access&#34;:
                pdfurl.append(x[&#34;url&#34;])

            if x[&#34;documentStyle&#34;] == &#34;html&#34; and x[&#34;availability&#34;] == &#34;Open access&#34;:
                htmlurl.append(x[&#34;url&#34;])
        paperpmcid = paper[&#34;pmcid&#34;]
        resultant_dict = self.make_initial_columns_for_paper_dict(
            paperpmcid, resultant_dict)
        resultant_dict[paperpmcid][&#34;full&#34;] = paper
        return htmlurl, paperpmcid, pdfurl, resultant_dict

    def add_fields_to_resultant_dict(self, htmlurl, paper, paper_number, pdfurl, dict_for_paper):
        &#34;&#34;&#34;
        Writes urls to dictionary

        :param htmlurl: list containing html urls for the paper

        :param paper: python dictionary of the paper

        :param paper_number: paper number to log

        :param pdfurl: list containing pdf urls for the paper

        :param dict_for_paper: python dictionary to write the urls to

        :return: dict_for_paper
        &#34;&#34;&#34;
        import logging
        try:
            dict_for_paper[self.HTMLLINKS] = htmlurl[0]
        except:
            logging.warning(
                f&#34;html url not found for paper {paper_number}&#34;)
        try:
            dict_for_paper[&#34;abstract&#34;] = paper[&#34;abstractText&#34;]
        except:
            logging.warning(
                f&#34;Abstract not found for paper {paper_number}&#34;)

        try:
            dict_for_paper[&#34;Keywords&#34;] = paper[&#34;keywordList&#34;][&#34;keyword&#34;]
        except:
            logging.warning(
                f&#34;Keywords not found for paper {paper_number}&#34;)
        try:
            dict_for_paper[self.PDFLINKS] = pdfurl[0]
        except:
            logging.warning(
                f&#34;pdf url not found for paper {paper_number}&#34;)
        try:
            dict_for_paper[self.JOURNALTITLE] = paper[&#34;journalInfo&#34;][&#34;journal&#34;][self.TITLE]
        except:
            logging.warning(
                f&#34;journalInfo not found for paper {paper_number}&#34;)
        try:
            dict_for_paper[self.AUTHORINFO
                           ] = paper[&#34;authorList&#34;][&#34;author&#34;][0][&#39;fullName&#39;]
        except:
            logging.warning(
                f&#34;Author list not found for paper {paper_number}&#34;)
        try:
            dict_for_paper[self.TITLE] = paper[self.TITLE]
        except:
            logging.warning(
                f&#34;Title not found for paper {paper_number}&#34;)

    def getxml(self, pmcid):
        &#34;&#34;&#34;
        Makes a query for the pmcid xml to eupmc rest.

        :param pmcid: pmcid of the paper to query for

        :return: query result
        &#34;&#34;&#34;
        import requests
        r = requests.get(
            f&#34;https://www.ebi.ac.uk/europepmc/webservices/rest/{pmcid}/fullTextXML&#34;)
        return r.content

    def getsupplementaryfiles(self, pmcid, directory_url, destination_url):
        &#34;&#34;&#34;
        Downloads the supplemetary marks for the paper having pmcid

        :param pmcid: pmcid to get the supplementary files

        :param directory_url: directory containg destination

        :param destination_url: path to write the supplementary files to
        &#34;&#34;&#34;
        import requests
        import os
        import logging
        r = requests.get(
            f&#34;https://www.ebi.ac.uk/europepmc/webservices/rest/{pmcid}/supplementaryFiles&#34;, stream=True)
        if not os.path.isdir(directory_url):
            os.makedirs(directory_url)
        with open(destination_url, &#39;wb&#39;) as fd:
            for chunk in r.iter_content(chunk_size=128):
                fd.write(chunk)
        logging.debug(f&#34;Wrote supplementary files for {pmcid}&#34;)

    def getreferences(self, pmcid, source):
        &#34;&#34;&#34;
        Gets references for the paper of pmcid

        :param pmcid: pmcid to get the references

        :param source: source to get the references from

        :return: references xml

        &#34;&#34;&#34;
        import requests
        r = requests.get(
            f&#34;https://www.ebi.ac.uk/europepmc/webservices/rest/{source}/{pmcid}/references?page=1&amp;pageSize=1000&amp;format=xml&#34;)
        return r.content

    def make_references(self, directory_url, paperid, source, referenceurl):
        &#39;&#39;&#39;
        Downloads the references for the paper with pmcid (paperid) to reference url

        :param directory_url: directory containing referenceurl

        :param paperid:  pmc id of the paper

        :param source: source to get the citations from

        :param referenceurl: path to write the references to
        &#39;&#39;&#39;
        getreferences = self.getreferences(
            paperid, source)
        self.writexml(directory_url, referenceurl, getreferences)

    def getcitations(self, pmcid, source):
        &#34;&#34;&#34;
        Gets citations for the paper of pmcid

        :param pmcid: pmcid to get the citations

        :param source: source to get the citations from

        :return: citations xml

        &#34;&#34;&#34;
        import requests
        r = requests.get(
            f&#34;https://www.ebi.ac.uk/europepmc/webservices/rest/{source}/{pmcid}/citations?page=1&amp;pageSize=1000&amp;format=xml&#34;)
        return r.content

    def writexml(self, directory_url, destination_url, content):
        &#34;&#34;&#34;
        writes xml to the destination

        :param directory_url: directory containg destination

        :param destination_url: path to write the xml to

        :param content: xml content
        &#34;&#34;&#34;
        import os
        if not os.path.isdir(directory_url):
            os.makedirs(directory_url)
        with open(destination_url, &#39;wb&#39;) as f:
            f.write(content)

    def make_citations(self, source, citationurl, directory_url, paperid):
        &#39;&#39;&#39;
        Downloads the citations for the paper with pmcid (paperid) to citation url

        :param source: source to get the citations from

        :param citationurl: path to write the citations to

        :param directory_url: directory containing citationurl

        :param paperid: pmc id of the paper
        &#39;&#39;&#39;
        getcitations = self.getcitations(
            paperid, source)
        self.writexml(directory_url, citationurl, getcitations)

    def makexmlfiles(self, final_xml_dict, getpdf=False, makecsv=False, makexml=False, references=False,
                     citations=False, supplementaryFiles=False):
        &#34;&#34;&#34;
        Writes the *pdf,*csv,*xml,*references,*citations,*supplementaryFiles for the individual papers

        :param final_xml_dict: Python dictionary containg all the papers

        :param getpdf(bool): whether to make pdfs

        :param makecsv(bool): whether to make csv for the metadata

        :param makexml(bool): whether to make xml file for the paper

        :param references(bool): whether to download references

        :param citations(bool): whether to download citations

        :param supplementaryFiles(bool): whether to download supplementary files

        &#34;&#34;&#34;
        import logging
        import os
        import time
        if makexml:
            super().log_making_xml()
        paper_number = 0
        for paper in final_xml_dict:
            start = time.time()
            paper_number += 1
            pmcid = paper
            tree = self.getxml(pmcid)
            citationurl, destination_url, directory_url, jsonurl, referenceurl, supplementaryfilesurl = self.get_urls_to_write_to(
                pmcid)
            paperdict = final_xml_dict[paper]
            paperid = paperdict[&#34;full&#34;][&#34;id&#34;]
            if references:
                self.make_references(directory_url, paperid,
                                     references, referenceurl)
                logging.info(f&#34;Made references for {pmcid}&#34;)
            if citations:
                self.make_citations(citations, citationurl,
                                    directory_url, paperid)
                logging.info(f&#34;Made Citations for {pmcid}&#34;)
            if supplementaryFiles:
                self.getsupplementaryfiles(
                    paperid, directory_url, supplementaryfilesurl)
                logging.info(f&#34;Made Supplementary files for {pmcid}&#34;)
            if not os.path.isdir(directory_url):
                os.makedirs(directory_url)
            condition_to_down, condition_to_download_csv, condition_to_download_json, condition_to_download_pdf = super().conditions_to_download(
                paperdict)
            if condition_to_down:
                if makexml:
                    super().writexml(directory_url, destination_url, tree)
                    logging.info(f&#34;*/Wrote xml for {pmcid}/&#34;)
                    paperdict[&#34;downloaded&#34;] = True
            if condition_to_download_pdf:
                if getpdf:
                    pdf_destination = os.path.join(
                        str(os.getcwd()), pmcid, &#34;fulltext.pdf&#34;)
                    if &#34;pdflinks&#34; in paperdict:
                        if len(paperdict[&#34;pdflinks&#34;]) &gt; 0:
                            super().writepdf(
                                paperdict[&#34;pdflinks&#34;], pdf_destination)
                            paperdict[&#34;pdfdownloaded&#34;] = True
                            logging.info(f&#34;Wrote the pdf file for {pmcid}&#34;)
            dict_to_write = super().clean_dict_for_csv(paperdict)
            if condition_to_download_json:
                super().makejson(jsonurl, dict_to_write)
                paperdict[&#34;jsondownloaded&#34;] = True
            if condition_to_download_csv:
                if makecsv:
                    self.make_csv(dict_to_write, pmcid)
                    paperdict[&#34;csvmade&#34;] = True
            super().makejson(os.path.join(
                str(os.getcwd()), &#39;eupmc_results.json&#39;), final_xml_dict)
            stop = time.time()
            logging.debug(f&#34;Time elapsed: {stop - start}&#34;)
            logging.debug(f&#34;*/Updating the json*/\n&#34;)

    def make_csv(self, dict_to_write, pmcid):
        &#34;&#34;&#34;
        Makes csv file for the dict_to_write (python dictionary for the fulltext).

        :param dict_to_write: Python dictionary to write the csv from

        :param pmcid: pmcid of the paper

        &#34;&#34;&#34;
        import pandas as pd
        import os
        df = pd.Series(dict_to_write).to_frame(
            &#39;Info_By_EuropePMC_Api&#39;)
        df.to_csv(os.path.join(
            str(os.getcwd()), pmcid, &#34;fulltext.csv&#34;))

    def conditions_to_download(self, paperdict):
        &#34;&#34;&#34;
        Writes the conditions to download pdf, json and csv

        :param paperdict: dictionary to write rules for
        &#34;&#34;&#34;
        condition_to_down = paperdict[&#34;downloaded&#34;] is False
        condition_to_download_pdf = paperdict[&#34;pdfdownloaded&#34;] is False
        condition_to_download_json = paperdict[&#34;jsondownloaded&#34;] is False
        condition_to_download_csv = paperdict[&#34;csvmade&#34;] is False
        return condition_to_down, condition_to_download_csv, condition_to_download_json, condition_to_download_pdf

    def get_urls_to_write_to(self, pmcid):
        &#34;&#34;&#34;
        :param pmcid: pmcid to write the urls for

        :return: tuple containing urls where files for the fulltext will be written
        &#34;&#34;&#34;
        import os
        destination_url = os.path.join(
            str(os.getcwd()), pmcid, &#34;fulltext.xml&#34;)
        directory_url = os.path.join(str(os.getcwd()), pmcid)
        jsonurl = os.path.join(
            str(os.getcwd()), pmcid, &#34;eupmc_result.json&#34;)
        referenceurl = os.path.join(
            str(os.getcwd()), pmcid, &#34;references.xml&#34;)
        citationurl = os.path.join(
            str(os.getcwd()), pmcid, &#34;citation.xml&#34;)
        supplementaryfilesurl = os.path.join(
            str(os.getcwd()), pmcid, &#34;supplementaryfiles.zip&#34;)
        return citationurl, destination_url, directory_url, jsonurl, referenceurl, supplementaryfilesurl

    def apipaperdownload(self, query, size, onlymakejson=False, getpdf=False, makecsv=False, makexml=False,
                         references=False, citations=False, supplementaryFiles=False, synonym=True):
        &#34;&#34;&#34;
        Downloads and writes papers along with the metadata for the given query

        :param query: Query to download papers for

        :param size: Number of papers to be downloaded

        :param *onlymakejson(bool): whether to only write the json files

        :param *getpdf(bool): whether to make pdf files

        :param *makecsv(bool): whether to make csv files

        :param *makexml(bool):whether to make xml files

        :param *references: Source to get the references from

        :param *citations: Source to get the citations from

        :param *supplementaryFiles(bool): whether to write supplementary files

        :param *synonym(bool): whether to also get files with query as the synonym of the given query
        &#34;&#34;&#34;
        import os
        query_result = self.europe_pmc.europepmc(query, size, synonym=synonym)
        self.makecsv(query_result, makecsv=makecsv)

        if not (onlymakejson):
            read_json = super().readjsondata(os.path.join(
                str(os.getcwd()), &#39;eupmc_results.json&#39;))
            self.makexmlfiles(read_json, getpdf=getpdf, makecsv=makecsv, makexml=makexml,
                              references=references, citations=citations, supplementaryFiles=supplementaryFiles)

    def updatecorpus(self, query, original_json, size, onlymakejson=False, getpdf=False, makecsv=False, makexml=False,
                     references=False, citations=False, supplementaryFiles=False, synonym=True):
        &#34;&#34;&#34;
        Updates the corpus with new papers

        :param query(str):  Query to download papers for

        :param original_json: Json of the original corpus in the form of python dictionary

        :param size(int): Number of new papers to download

        :param *onlymakejson(bool): whether to only write json files

        :param *getpdf(bool): whether to make pdf files

        :param *makecsv(bool): whether to make csv files

        :param *makexml(bool): whether to make xml files

        :param *references: Source to get the references from

        :param *citations: Source to get the citations from

        :param *supplementaryFiles(bool): whether to write supplementary files

        :param *synonym(bool): whether to also get files with query as the synonym of the given query

        &#34;&#34;&#34;
        import os
        query_result = self.europe_pmc.europepmc(
            query, size, update=original_json, synonym=synonym)
        self.makecsv(query_result, makecsv=makecsv,
                     update=original_json)
        if not onlymakejson:
            read_json = super().readjsondata(os.path.join(
                str(os.getcwd()), &#39;eupmc_results.json&#39;))
            self.makexmlfiles(read_json, getpdf=getpdf,
                              makecsv=makecsv, makexml=makexml, references=references, citations=citations,
                              supplementaryFiles=supplementaryFiles)

    def noexecute(self, query, synonym=True):
        &#34;&#34;&#34;
        Tells how many hits found for the query

        :param query:

        :param synonym:
        &#34;&#34;&#34;
        import logging
        builtqueryparams = super().buildquery(
            &#39;*&#39;, 25, query, synonym=synonym)
        HEADERS = &#39;headers&#39;
        PAYLOAD = &#39;payload&#39;
        result = super().postquery(
            builtqueryparams[HEADERS], builtqueryparams[PAYLOAD])
        totalhits = result[&#39;responseWrapper&#39;][&#39;hitCount&#39;]
        logging.info(f&#39;Total number of hits for the query are {totalhits}&#39;)

    def handlecli(self):
        &#34;&#34;&#34;
        Handles the command line interface using argparse
        &#34;&#34;&#34;
        version = &#34;0.0.3.2&#34;
        import argparse
        import os
        import logging
        import sys
        from time import gmtime, strftime
        default_path = strftime(&#34;%Y_%m_%d_%H_%M_%S&#34;, gmtime())
        parser = argparse.ArgumentParser(
            description=f&#34;Welcome to Pygetpapers version {version}. -h or --help for help&#34;)
        parser.add_argument(&#34;-v&#34;, &#34;--version&#34;,
                            default=False, action=&#34;store_true&#34;, help=&#34;output the version number&#34;)
        parser.add_argument(&#34;-q&#34;, &#34;--query&#34;,
                            type=str, default=False,
                            help=&#34;query string transmitted to repository API. Eg. \&#34;Artificial Intelligence\&#34; or \&#34;Plant Parts\&#34;. To escape special characters within the quotes, use backslash. Incase of nested quotes, ensure that the initial quotes are double and the qutoes inside are single. For eg: `&#39;(LICENSE:\&#34;cc by\&#34; OR LICENSE:\&#34;cc-by\&#34;) AND METHODS:\&#34;transcriptome assembly\&#34;&#39; ` is wrong. We should instead use `\&#34;(LICENSE:&#39;cc by&#39; OR LICENSE:&#39;cc-by&#39;) AND METHODS:&#39;transcriptome assembly&#39;\&#34;` &#34;)

        parser.add_argument(&#34;-o&#34;, &#34;--output&#34;,
                            type=str, help=&#34;output directory (Default: Folder inside current working directory named )&#34;, default=os.path.join(os.getcwd(), default_path))
        parser.add_argument(&#34;-x&#34;, &#34;--xml&#34;, default=False, action=&#39;store_true&#39;,
                            help=&#34;download fulltext XMLs if available&#34;)
        parser.add_argument(&#34;-p&#34;, &#34;--pdf&#34;, default=False, action=&#39;store_true&#39;,
                            help=&#34;download fulltext PDFs if available&#34;)
        parser.add_argument(&#34;-s&#34;, &#34;--supp&#34;, default=False, action=&#39;store_true&#39;,
                            help=&#34;download supplementary files if available     &#34;)
        parser.add_argument(&#34;--references&#34;,
                            type=str, default=False,
                            help=&#34;Download references if available. Requires source for references (AGR,CBA,CTX,ETH,HIR,MED,PAT,PMC,PPR).&#34;)
        parser.add_argument(&#34;-n&#34;, &#34;--noexecute&#34;, default=False, action=&#39;store_true&#39;,
                            help=&#34;report how many results match the query, but don&#39;t actually download anything&#34;)

        parser.add_argument(&#34;--citations&#34;, type=str, default=False,
                            help=&#34;Download citations if available. Requires source for citations (AGR,CBA,CTX,ETH,HIR,MED,PAT,PMC,PPR).&#34;)
        parser.add_argument(&#34;-l&#34;, &#39;--loglevel&#39;, default=&#34;info&#34;,
                            help=&#34;Provide logging level.  Example --log warning &lt;&lt;info,warning,debug,error,critical&gt;&gt;, default=&#39;info&#39;&#34;)
        parser.add_argument(&#34;-f&#34;, &#34;--logfile&#34;, default=False,
                            type=str,
                            help=&#34;save log to specified file in output directory as well as printing to terminal&#34;)
        parser.add_argument(&#34;-k&#34;, &#34;--limit&#34;, default=100,
                            type=int, help=&#34;maximum number of hits (default: 100)&#34;)

        parser.add_argument(&#39;-r&#39;, &#34;--restart&#34;, default=False,
                            type=str,
                            help=&#34;Reads the json and makes the xml files. Takes the path to the json as the input&#34;)

        parser.add_argument(&#34;-u&#34;, &#34;--update&#34;, default=False,
                            type=str,
                            help=&#34;Updates the corpus by downloading new papers. Takes the path of metadata json file of the orignal corpus as the input. Requires -k or --limit (If not provided, default will be used) and -q or --query (must be provided) to be given. Takes the path to the json as the input.&#34;)
        parser.add_argument(&#34;--onlyquery&#34;, action=&#39;store_true&#39;,
                            help=&#34;Saves json file containing the result of the query in storage. The json file can be given to --restart to download the papers later.&#34;)
        parser.add_argument(&#34;-c&#34;, &#34;--makecsv&#34;, default=False, action=&#39;store_true&#39;,
                            help=&#34;Stores the per-document metadata as csv. Works only with --api method.&#34;)
        parser.add_argument(&#34;--synonym&#34;, default=False, action=&#39;store_true&#39;,
                            help=&#34;Results contain synonyms as well.&#34;)
        if len(sys.argv) == 1:
            parser.print_help(sys.stderr)
            sys.exit()
        args = parser.parse_args()

        if os.path.exists(args.output):
            os.chdir(args.output)
        else:
            os.makedirs(args.output)
            os.chdir(args.output)
        levels = {
            &#39;critical&#39;: logging.CRITICAL,
            &#39;error&#39;: logging.ERROR,
            &#39;warn&#39;: logging.WARNING,
            &#39;warning&#39;: logging.WARNING,
            &#39;info&#39;: logging.INFO,
            &#39;debug&#39;: logging.DEBUG
        }
        level = levels.get(args.loglevel.lower())
        if args.logfile:
            logging.basicConfig(filename=args.logfile,
                                level=level, filemode=&#39;w&#39;)
            console = logging.StreamHandler()

            console.setLevel(level)
            formatter = logging.Formatter(&#39;%(levelname)s: %(message)s&#39;)
            # tell the handler to use this format
            console.setFormatter(formatter)
            logging.getLogger().addHandler(console)
            logging.info(f&#39;Making log file at {args.logfile}&#39;)

        else:
            logging.basicConfig(
                level=level, format=&#39;%(levelname)s: %(message)s&#39;)

        if not args.query:
            logging.warning(&#39;Please specify a query&#39;)
            sys.exit(1)

        if args.noexecute:
            self.noexecute(args.query, synonym=args.synonym)
        elif args.version:
            logging.info(version)
        elif args.restart:
            import os
            import logging
            read_json = super().readjsondata(args.restart)
            os.chdir(os.path.dirname(args.restart))
            self.makexmlfiles(read_json, getpdf=args.pdf, makecsv=args.makecsv, makexml=args.xml,
                              references=args.references, citations=args.citations, supplementaryFiles=args.supp)
        elif args.update:
            read_json = super().readjsondata(args.update)
            os.chdir(os.path.dirname(args.update))
            self.updatecorpus(args.query, read_json, args.limit, getpdf=args.pdf,
                              makecsv=args.makecsv, makexml=args.xml, references=args.references,
                              citations=args.citations, supplementaryFiles=args.supp, synonym=args.synonym)
        else:
            if args.query:
                self.apipaperdownload(args.query, args.limit,
                                      onlymakejson=args.onlyquery, getpdf=args.pdf, makecsv=args.makecsv,
                                      makexml=args.xml, references=args.references, citations=args.citations,
                                      supplementaryFiles=args.supp, synonym=args.synonym)


def demo():
    &#34;&#34;&#34;
    Shows demo to use the library to download papers
    &#34;&#34;&#34;
    callgetpapers = pygetpapers()
    query = &#34;artificial intelligence&#34;
    numberofpapers = 210
    callgetpapers.apipaperdownload(query, numberofpapers)


def main():
    &#34;&#34;&#34;
    Runs the CLI
    &#34;&#34;&#34;
    callpygetpapers = pygetpapers()
    callpygetpapers.handlecli()


if __name__ == &#34;__main__&#34;:
    main()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="pygetpapers.pygetpapers.demo"><code class="name flex">
<span>def <span class="ident">demo</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Shows demo to use the library to download papers</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def demo():
    &#34;&#34;&#34;
    Shows demo to use the library to download papers
    &#34;&#34;&#34;
    callgetpapers = pygetpapers()
    query = &#34;artificial intelligence&#34;
    numberofpapers = 210
    callgetpapers.apipaperdownload(query, numberofpapers)</code></pre>
</details>
</dd>
<dt id="pygetpapers.pygetpapers.main"><code class="name flex">
<span>def <span class="ident">main</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Runs the CLI</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def main():
    &#34;&#34;&#34;
    Runs the CLI
    &#34;&#34;&#34;
    callpygetpapers = pygetpapers()
    callpygetpapers.handlecli()</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="pygetpapers.pygetpapers.pygetpapers"><code class="flex name class">
<span>class <span class="ident">pygetpapers</span></span>
</code></dt>
<dd>
<div class="desc"><p>This function makes all the constants</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class pygetpapers(download_tools):

    def __init__(self):
        &#34;&#34;&#34;
        This function makes all the constants
        &#34;&#34;&#34;
        import os
        self.LOGGING_URL = os.path.join(str(os.getcwd()), &#39;*&#39;, &#39;fulltext.xml&#39;)
        self.EUPMCJSON = os.path.join(str(os.getcwd()), &#39;eupmc_results.json&#39;)
        self.EUPMCCSVURL = os.path.join(str(os.getcwd()), &#39;europe_pmc.csv&#39;)
        self.TITLE = &#34;title&#34;
        self.AUTHORINFO = &#34;authorinfo&#34;
        self.JOURNALTITLE = &#34;journaltitle&#34;
        self.PDFLINKS = &#34;pdflinks&#34;
        self.HTMLLINKS = &#34;htmllinks&#34;
        self.PMCID = &#34;pmcid&#34;
        self.RESPONSE_WRAPPER = &#34;responseWrapper&#34;
        self.CURSOR_MARK = &#34;nextCursorMark&#34;
        self.europe_pmc = europe_pmc()
        self.directory_url = os.path.join(
            str(os.getcwd()))

    def make_initial_columns_for_paper_dict(self, pmcid, resultant_dict):
        &#34;&#34;&#34;
        :param pmcid: pmcid of the paper for which fields will be created
        :param resultant_dict: dict in which the fields will be created
        :return: dict with the initial fields created for pmcid
        &#34;&#34;&#34;
        resultant_dict[pmcid] = {}
        resultant_dict[pmcid][&#34;downloaded&#34;] = False
        resultant_dict[pmcid][&#34;pdfdownloaded&#34;] = False
        resultant_dict[pmcid][&#34;jsondownloaded&#34;] = False
        resultant_dict[pmcid][&#34;csvmade&#34;] = False
        return resultant_dict
    # this is the function that will the the result from search and will download and save the files.

    def makecsv(self, searchvariable, makecsv=False, update=False):
        &#34;&#34;&#34;
        Writes the json and *csv for searchvaraible dict

        :param searchvariable(dict): Python dictionary which contains all the research papers (given by europe_pmc.europepmc))

        :param makecsv(bool): whether to make csv files

        :param update(dict): if provided, will add the research papers to the searchvariable dict

        :return: searchvariable
        &#34;&#34;&#34;
        import pandas as pd
        import json
        import os
        import logging
        resultant_dict = {}
        for paper_number, papers in enumerate(searchvariable):
            output_dict = json.loads(json.dumps(papers))
            for paper in output_dict:
                if self.PMCID in paper:
                    paper_number += 1
                    htmlurl, paperpmcid, pdfurl, resultant_dict = self.write_meta_data_for_paper(
                        paper, paper_number, resultant_dict)
                    self.add_fields_to_resultant_dict(
                        htmlurl, paper, paper_number, pdfurl, resultant_dict[paperpmcid])
                    logging.debug(
                        f&#39;Wrote Meta Data to a dictionary that will be written to all the chosen metadata file formats for paper {paperpmcid}&#39;)
        if update:
            resultant_dict.update(update)
        directory_url = os.path.join(
            str(os.getcwd()))
        jsonurl = os.path.join(
            str(os.getcwd()), &#39;eupmc_results.json&#39;)
        super().check_or_make_directory(directory_url)
        self.makejson(jsonurl, resultant_dict)
        resultant_dict_for_csv = super().make_dict_for_csv(resultant_dict)
        df = pd.DataFrame.from_dict(resultant_dict_for_csv, )
        df_transposed = df.T
        if makecsv:
            super().write_or_append_to_csv(df_transposed)
        return searchvariable

    def write_meta_data_for_paper(self, paper, paper_number, resultant_dict):
        &#34;&#34;&#34;
        Adds pdf and html url as well as makes the paper key in resultant_dict

        :param paper: python dictionary for the paper

        :param paper_number: paper number to log

        :param resultant_dict: dictionary to add paper as well as pdf,html url to

        :return: (htmlurl, paperpmcid, pdfurl, resultant_dict)
        &#34;&#34;&#34;
        import logging
        logging.debug(
            f&#34;Reading Query Result for paper {paper_number}&#34;)
        pdfurl = []
        htmlurl = []
        for x in paper[&#34;fullTextUrlList&#34;][&#34;fullTextUrl&#34;]:
            if x[&#34;documentStyle&#34;] == &#34;pdf&#34; and x[&#34;availability&#34;] == &#34;Open access&#34;:
                pdfurl.append(x[&#34;url&#34;])

            if x[&#34;documentStyle&#34;] == &#34;html&#34; and x[&#34;availability&#34;] == &#34;Open access&#34;:
                htmlurl.append(x[&#34;url&#34;])
        paperpmcid = paper[&#34;pmcid&#34;]
        resultant_dict = self.make_initial_columns_for_paper_dict(
            paperpmcid, resultant_dict)
        resultant_dict[paperpmcid][&#34;full&#34;] = paper
        return htmlurl, paperpmcid, pdfurl, resultant_dict

    def add_fields_to_resultant_dict(self, htmlurl, paper, paper_number, pdfurl, dict_for_paper):
        &#34;&#34;&#34;
        Writes urls to dictionary

        :param htmlurl: list containing html urls for the paper

        :param paper: python dictionary of the paper

        :param paper_number: paper number to log

        :param pdfurl: list containing pdf urls for the paper

        :param dict_for_paper: python dictionary to write the urls to

        :return: dict_for_paper
        &#34;&#34;&#34;
        import logging
        try:
            dict_for_paper[self.HTMLLINKS] = htmlurl[0]
        except:
            logging.warning(
                f&#34;html url not found for paper {paper_number}&#34;)
        try:
            dict_for_paper[&#34;abstract&#34;] = paper[&#34;abstractText&#34;]
        except:
            logging.warning(
                f&#34;Abstract not found for paper {paper_number}&#34;)

        try:
            dict_for_paper[&#34;Keywords&#34;] = paper[&#34;keywordList&#34;][&#34;keyword&#34;]
        except:
            logging.warning(
                f&#34;Keywords not found for paper {paper_number}&#34;)
        try:
            dict_for_paper[self.PDFLINKS] = pdfurl[0]
        except:
            logging.warning(
                f&#34;pdf url not found for paper {paper_number}&#34;)
        try:
            dict_for_paper[self.JOURNALTITLE] = paper[&#34;journalInfo&#34;][&#34;journal&#34;][self.TITLE]
        except:
            logging.warning(
                f&#34;journalInfo not found for paper {paper_number}&#34;)
        try:
            dict_for_paper[self.AUTHORINFO
                           ] = paper[&#34;authorList&#34;][&#34;author&#34;][0][&#39;fullName&#39;]
        except:
            logging.warning(
                f&#34;Author list not found for paper {paper_number}&#34;)
        try:
            dict_for_paper[self.TITLE] = paper[self.TITLE]
        except:
            logging.warning(
                f&#34;Title not found for paper {paper_number}&#34;)

    def getxml(self, pmcid):
        &#34;&#34;&#34;
        Makes a query for the pmcid xml to eupmc rest.

        :param pmcid: pmcid of the paper to query for

        :return: query result
        &#34;&#34;&#34;
        import requests
        r = requests.get(
            f&#34;https://www.ebi.ac.uk/europepmc/webservices/rest/{pmcid}/fullTextXML&#34;)
        return r.content

    def getsupplementaryfiles(self, pmcid, directory_url, destination_url):
        &#34;&#34;&#34;
        Downloads the supplemetary marks for the paper having pmcid

        :param pmcid: pmcid to get the supplementary files

        :param directory_url: directory containg destination

        :param destination_url: path to write the supplementary files to
        &#34;&#34;&#34;
        import requests
        import os
        import logging
        r = requests.get(
            f&#34;https://www.ebi.ac.uk/europepmc/webservices/rest/{pmcid}/supplementaryFiles&#34;, stream=True)
        if not os.path.isdir(directory_url):
            os.makedirs(directory_url)
        with open(destination_url, &#39;wb&#39;) as fd:
            for chunk in r.iter_content(chunk_size=128):
                fd.write(chunk)
        logging.debug(f&#34;Wrote supplementary files for {pmcid}&#34;)

    def getreferences(self, pmcid, source):
        &#34;&#34;&#34;
        Gets references for the paper of pmcid

        :param pmcid: pmcid to get the references

        :param source: source to get the references from

        :return: references xml

        &#34;&#34;&#34;
        import requests
        r = requests.get(
            f&#34;https://www.ebi.ac.uk/europepmc/webservices/rest/{source}/{pmcid}/references?page=1&amp;pageSize=1000&amp;format=xml&#34;)
        return r.content

    def make_references(self, directory_url, paperid, source, referenceurl):
        &#39;&#39;&#39;
        Downloads the references for the paper with pmcid (paperid) to reference url

        :param directory_url: directory containing referenceurl

        :param paperid:  pmc id of the paper

        :param source: source to get the citations from

        :param referenceurl: path to write the references to
        &#39;&#39;&#39;
        getreferences = self.getreferences(
            paperid, source)
        self.writexml(directory_url, referenceurl, getreferences)

    def getcitations(self, pmcid, source):
        &#34;&#34;&#34;
        Gets citations for the paper of pmcid

        :param pmcid: pmcid to get the citations

        :param source: source to get the citations from

        :return: citations xml

        &#34;&#34;&#34;
        import requests
        r = requests.get(
            f&#34;https://www.ebi.ac.uk/europepmc/webservices/rest/{source}/{pmcid}/citations?page=1&amp;pageSize=1000&amp;format=xml&#34;)
        return r.content

    def writexml(self, directory_url, destination_url, content):
        &#34;&#34;&#34;
        writes xml to the destination

        :param directory_url: directory containg destination

        :param destination_url: path to write the xml to

        :param content: xml content
        &#34;&#34;&#34;
        import os
        if not os.path.isdir(directory_url):
            os.makedirs(directory_url)
        with open(destination_url, &#39;wb&#39;) as f:
            f.write(content)

    def make_citations(self, source, citationurl, directory_url, paperid):
        &#39;&#39;&#39;
        Downloads the citations for the paper with pmcid (paperid) to citation url

        :param source: source to get the citations from

        :param citationurl: path to write the citations to

        :param directory_url: directory containing citationurl

        :param paperid: pmc id of the paper
        &#39;&#39;&#39;
        getcitations = self.getcitations(
            paperid, source)
        self.writexml(directory_url, citationurl, getcitations)

    def makexmlfiles(self, final_xml_dict, getpdf=False, makecsv=False, makexml=False, references=False,
                     citations=False, supplementaryFiles=False):
        &#34;&#34;&#34;
        Writes the *pdf,*csv,*xml,*references,*citations,*supplementaryFiles for the individual papers

        :param final_xml_dict: Python dictionary containg all the papers

        :param getpdf(bool): whether to make pdfs

        :param makecsv(bool): whether to make csv for the metadata

        :param makexml(bool): whether to make xml file for the paper

        :param references(bool): whether to download references

        :param citations(bool): whether to download citations

        :param supplementaryFiles(bool): whether to download supplementary files

        &#34;&#34;&#34;
        import logging
        import os
        import time
        if makexml:
            super().log_making_xml()
        paper_number = 0
        for paper in final_xml_dict:
            start = time.time()
            paper_number += 1
            pmcid = paper
            tree = self.getxml(pmcid)
            citationurl, destination_url, directory_url, jsonurl, referenceurl, supplementaryfilesurl = self.get_urls_to_write_to(
                pmcid)
            paperdict = final_xml_dict[paper]
            paperid = paperdict[&#34;full&#34;][&#34;id&#34;]
            if references:
                self.make_references(directory_url, paperid,
                                     references, referenceurl)
                logging.info(f&#34;Made references for {pmcid}&#34;)
            if citations:
                self.make_citations(citations, citationurl,
                                    directory_url, paperid)
                logging.info(f&#34;Made Citations for {pmcid}&#34;)
            if supplementaryFiles:
                self.getsupplementaryfiles(
                    paperid, directory_url, supplementaryfilesurl)
                logging.info(f&#34;Made Supplementary files for {pmcid}&#34;)
            if not os.path.isdir(directory_url):
                os.makedirs(directory_url)
            condition_to_down, condition_to_download_csv, condition_to_download_json, condition_to_download_pdf = super().conditions_to_download(
                paperdict)
            if condition_to_down:
                if makexml:
                    super().writexml(directory_url, destination_url, tree)
                    logging.info(f&#34;*/Wrote xml for {pmcid}/&#34;)
                    paperdict[&#34;downloaded&#34;] = True
            if condition_to_download_pdf:
                if getpdf:
                    pdf_destination = os.path.join(
                        str(os.getcwd()), pmcid, &#34;fulltext.pdf&#34;)
                    if &#34;pdflinks&#34; in paperdict:
                        if len(paperdict[&#34;pdflinks&#34;]) &gt; 0:
                            super().writepdf(
                                paperdict[&#34;pdflinks&#34;], pdf_destination)
                            paperdict[&#34;pdfdownloaded&#34;] = True
                            logging.info(f&#34;Wrote the pdf file for {pmcid}&#34;)
            dict_to_write = super().clean_dict_for_csv(paperdict)
            if condition_to_download_json:
                super().makejson(jsonurl, dict_to_write)
                paperdict[&#34;jsondownloaded&#34;] = True
            if condition_to_download_csv:
                if makecsv:
                    self.make_csv(dict_to_write, pmcid)
                    paperdict[&#34;csvmade&#34;] = True
            super().makejson(os.path.join(
                str(os.getcwd()), &#39;eupmc_results.json&#39;), final_xml_dict)
            stop = time.time()
            logging.debug(f&#34;Time elapsed: {stop - start}&#34;)
            logging.debug(f&#34;*/Updating the json*/\n&#34;)

    def make_csv(self, dict_to_write, pmcid):
        &#34;&#34;&#34;
        Makes csv file for the dict_to_write (python dictionary for the fulltext).

        :param dict_to_write: Python dictionary to write the csv from

        :param pmcid: pmcid of the paper

        &#34;&#34;&#34;
        import pandas as pd
        import os
        df = pd.Series(dict_to_write).to_frame(
            &#39;Info_By_EuropePMC_Api&#39;)
        df.to_csv(os.path.join(
            str(os.getcwd()), pmcid, &#34;fulltext.csv&#34;))

    def conditions_to_download(self, paperdict):
        &#34;&#34;&#34;
        Writes the conditions to download pdf, json and csv

        :param paperdict: dictionary to write rules for
        &#34;&#34;&#34;
        condition_to_down = paperdict[&#34;downloaded&#34;] is False
        condition_to_download_pdf = paperdict[&#34;pdfdownloaded&#34;] is False
        condition_to_download_json = paperdict[&#34;jsondownloaded&#34;] is False
        condition_to_download_csv = paperdict[&#34;csvmade&#34;] is False
        return condition_to_down, condition_to_download_csv, condition_to_download_json, condition_to_download_pdf

    def get_urls_to_write_to(self, pmcid):
        &#34;&#34;&#34;
        :param pmcid: pmcid to write the urls for

        :return: tuple containing urls where files for the fulltext will be written
        &#34;&#34;&#34;
        import os
        destination_url = os.path.join(
            str(os.getcwd()), pmcid, &#34;fulltext.xml&#34;)
        directory_url = os.path.join(str(os.getcwd()), pmcid)
        jsonurl = os.path.join(
            str(os.getcwd()), pmcid, &#34;eupmc_result.json&#34;)
        referenceurl = os.path.join(
            str(os.getcwd()), pmcid, &#34;references.xml&#34;)
        citationurl = os.path.join(
            str(os.getcwd()), pmcid, &#34;citation.xml&#34;)
        supplementaryfilesurl = os.path.join(
            str(os.getcwd()), pmcid, &#34;supplementaryfiles.zip&#34;)
        return citationurl, destination_url, directory_url, jsonurl, referenceurl, supplementaryfilesurl

    def apipaperdownload(self, query, size, onlymakejson=False, getpdf=False, makecsv=False, makexml=False,
                         references=False, citations=False, supplementaryFiles=False, synonym=True):
        &#34;&#34;&#34;
        Downloads and writes papers along with the metadata for the given query

        :param query: Query to download papers for

        :param size: Number of papers to be downloaded

        :param *onlymakejson(bool): whether to only write the json files

        :param *getpdf(bool): whether to make pdf files

        :param *makecsv(bool): whether to make csv files

        :param *makexml(bool):whether to make xml files

        :param *references: Source to get the references from

        :param *citations: Source to get the citations from

        :param *supplementaryFiles(bool): whether to write supplementary files

        :param *synonym(bool): whether to also get files with query as the synonym of the given query
        &#34;&#34;&#34;
        import os
        query_result = self.europe_pmc.europepmc(query, size, synonym=synonym)
        self.makecsv(query_result, makecsv=makecsv)

        if not (onlymakejson):
            read_json = super().readjsondata(os.path.join(
                str(os.getcwd()), &#39;eupmc_results.json&#39;))
            self.makexmlfiles(read_json, getpdf=getpdf, makecsv=makecsv, makexml=makexml,
                              references=references, citations=citations, supplementaryFiles=supplementaryFiles)

    def updatecorpus(self, query, original_json, size, onlymakejson=False, getpdf=False, makecsv=False, makexml=False,
                     references=False, citations=False, supplementaryFiles=False, synonym=True):
        &#34;&#34;&#34;
        Updates the corpus with new papers

        :param query(str):  Query to download papers for

        :param original_json: Json of the original corpus in the form of python dictionary

        :param size(int): Number of new papers to download

        :param *onlymakejson(bool): whether to only write json files

        :param *getpdf(bool): whether to make pdf files

        :param *makecsv(bool): whether to make csv files

        :param *makexml(bool): whether to make xml files

        :param *references: Source to get the references from

        :param *citations: Source to get the citations from

        :param *supplementaryFiles(bool): whether to write supplementary files

        :param *synonym(bool): whether to also get files with query as the synonym of the given query

        &#34;&#34;&#34;
        import os
        query_result = self.europe_pmc.europepmc(
            query, size, update=original_json, synonym=synonym)
        self.makecsv(query_result, makecsv=makecsv,
                     update=original_json)
        if not onlymakejson:
            read_json = super().readjsondata(os.path.join(
                str(os.getcwd()), &#39;eupmc_results.json&#39;))
            self.makexmlfiles(read_json, getpdf=getpdf,
                              makecsv=makecsv, makexml=makexml, references=references, citations=citations,
                              supplementaryFiles=supplementaryFiles)

    def noexecute(self, query, synonym=True):
        &#34;&#34;&#34;
        Tells how many hits found for the query

        :param query:

        :param synonym:
        &#34;&#34;&#34;
        import logging
        builtqueryparams = super().buildquery(
            &#39;*&#39;, 25, query, synonym=synonym)
        HEADERS = &#39;headers&#39;
        PAYLOAD = &#39;payload&#39;
        result = super().postquery(
            builtqueryparams[HEADERS], builtqueryparams[PAYLOAD])
        totalhits = result[&#39;responseWrapper&#39;][&#39;hitCount&#39;]
        logging.info(f&#39;Total number of hits for the query are {totalhits}&#39;)

    def handlecli(self):
        &#34;&#34;&#34;
        Handles the command line interface using argparse
        &#34;&#34;&#34;
        version = &#34;0.0.3.2&#34;
        import argparse
        import os
        import logging
        import sys
        from time import gmtime, strftime
        default_path = strftime(&#34;%Y_%m_%d_%H_%M_%S&#34;, gmtime())
        parser = argparse.ArgumentParser(
            description=f&#34;Welcome to Pygetpapers version {version}. -h or --help for help&#34;)
        parser.add_argument(&#34;-v&#34;, &#34;--version&#34;,
                            default=False, action=&#34;store_true&#34;, help=&#34;output the version number&#34;)
        parser.add_argument(&#34;-q&#34;, &#34;--query&#34;,
                            type=str, default=False,
                            help=&#34;query string transmitted to repository API. Eg. \&#34;Artificial Intelligence\&#34; or \&#34;Plant Parts\&#34;. To escape special characters within the quotes, use backslash. Incase of nested quotes, ensure that the initial quotes are double and the qutoes inside are single. For eg: `&#39;(LICENSE:\&#34;cc by\&#34; OR LICENSE:\&#34;cc-by\&#34;) AND METHODS:\&#34;transcriptome assembly\&#34;&#39; ` is wrong. We should instead use `\&#34;(LICENSE:&#39;cc by&#39; OR LICENSE:&#39;cc-by&#39;) AND METHODS:&#39;transcriptome assembly&#39;\&#34;` &#34;)

        parser.add_argument(&#34;-o&#34;, &#34;--output&#34;,
                            type=str, help=&#34;output directory (Default: Folder inside current working directory named )&#34;, default=os.path.join(os.getcwd(), default_path))
        parser.add_argument(&#34;-x&#34;, &#34;--xml&#34;, default=False, action=&#39;store_true&#39;,
                            help=&#34;download fulltext XMLs if available&#34;)
        parser.add_argument(&#34;-p&#34;, &#34;--pdf&#34;, default=False, action=&#39;store_true&#39;,
                            help=&#34;download fulltext PDFs if available&#34;)
        parser.add_argument(&#34;-s&#34;, &#34;--supp&#34;, default=False, action=&#39;store_true&#39;,
                            help=&#34;download supplementary files if available     &#34;)
        parser.add_argument(&#34;--references&#34;,
                            type=str, default=False,
                            help=&#34;Download references if available. Requires source for references (AGR,CBA,CTX,ETH,HIR,MED,PAT,PMC,PPR).&#34;)
        parser.add_argument(&#34;-n&#34;, &#34;--noexecute&#34;, default=False, action=&#39;store_true&#39;,
                            help=&#34;report how many results match the query, but don&#39;t actually download anything&#34;)

        parser.add_argument(&#34;--citations&#34;, type=str, default=False,
                            help=&#34;Download citations if available. Requires source for citations (AGR,CBA,CTX,ETH,HIR,MED,PAT,PMC,PPR).&#34;)
        parser.add_argument(&#34;-l&#34;, &#39;--loglevel&#39;, default=&#34;info&#34;,
                            help=&#34;Provide logging level.  Example --log warning &lt;&lt;info,warning,debug,error,critical&gt;&gt;, default=&#39;info&#39;&#34;)
        parser.add_argument(&#34;-f&#34;, &#34;--logfile&#34;, default=False,
                            type=str,
                            help=&#34;save log to specified file in output directory as well as printing to terminal&#34;)
        parser.add_argument(&#34;-k&#34;, &#34;--limit&#34;, default=100,
                            type=int, help=&#34;maximum number of hits (default: 100)&#34;)

        parser.add_argument(&#39;-r&#39;, &#34;--restart&#34;, default=False,
                            type=str,
                            help=&#34;Reads the json and makes the xml files. Takes the path to the json as the input&#34;)

        parser.add_argument(&#34;-u&#34;, &#34;--update&#34;, default=False,
                            type=str,
                            help=&#34;Updates the corpus by downloading new papers. Takes the path of metadata json file of the orignal corpus as the input. Requires -k or --limit (If not provided, default will be used) and -q or --query (must be provided) to be given. Takes the path to the json as the input.&#34;)
        parser.add_argument(&#34;--onlyquery&#34;, action=&#39;store_true&#39;,
                            help=&#34;Saves json file containing the result of the query in storage. The json file can be given to --restart to download the papers later.&#34;)
        parser.add_argument(&#34;-c&#34;, &#34;--makecsv&#34;, default=False, action=&#39;store_true&#39;,
                            help=&#34;Stores the per-document metadata as csv. Works only with --api method.&#34;)
        parser.add_argument(&#34;--synonym&#34;, default=False, action=&#39;store_true&#39;,
                            help=&#34;Results contain synonyms as well.&#34;)
        if len(sys.argv) == 1:
            parser.print_help(sys.stderr)
            sys.exit()
        args = parser.parse_args()

        if os.path.exists(args.output):
            os.chdir(args.output)
        else:
            os.makedirs(args.output)
            os.chdir(args.output)
        levels = {
            &#39;critical&#39;: logging.CRITICAL,
            &#39;error&#39;: logging.ERROR,
            &#39;warn&#39;: logging.WARNING,
            &#39;warning&#39;: logging.WARNING,
            &#39;info&#39;: logging.INFO,
            &#39;debug&#39;: logging.DEBUG
        }
        level = levels.get(args.loglevel.lower())
        if args.logfile:
            logging.basicConfig(filename=args.logfile,
                                level=level, filemode=&#39;w&#39;)
            console = logging.StreamHandler()

            console.setLevel(level)
            formatter = logging.Formatter(&#39;%(levelname)s: %(message)s&#39;)
            # tell the handler to use this format
            console.setFormatter(formatter)
            logging.getLogger().addHandler(console)
            logging.info(f&#39;Making log file at {args.logfile}&#39;)

        else:
            logging.basicConfig(
                level=level, format=&#39;%(levelname)s: %(message)s&#39;)

        if not args.query:
            logging.warning(&#39;Please specify a query&#39;)
            sys.exit(1)

        if args.noexecute:
            self.noexecute(args.query, synonym=args.synonym)
        elif args.version:
            logging.info(version)
        elif args.restart:
            import os
            import logging
            read_json = super().readjsondata(args.restart)
            os.chdir(os.path.dirname(args.restart))
            self.makexmlfiles(read_json, getpdf=args.pdf, makecsv=args.makecsv, makexml=args.xml,
                              references=args.references, citations=args.citations, supplementaryFiles=args.supp)
        elif args.update:
            read_json = super().readjsondata(args.update)
            os.chdir(os.path.dirname(args.update))
            self.updatecorpus(args.query, read_json, args.limit, getpdf=args.pdf,
                              makecsv=args.makecsv, makexml=args.xml, references=args.references,
                              citations=args.citations, supplementaryFiles=args.supp, synonym=args.synonym)
        else:
            if args.query:
                self.apipaperdownload(args.query, args.limit,
                                      onlymakejson=args.onlyquery, getpdf=args.pdf, makecsv=args.makecsv,
                                      makexml=args.xml, references=args.references, citations=args.citations,
                                      supplementaryFiles=args.supp, synonym=args.synonym)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="pygetpapers.download_tools.download_tools" href="download_tools.html#pygetpapers.download_tools.download_tools">download_tools</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="pygetpapers.pygetpapers.pygetpapers.add_fields_to_resultant_dict"><code class="name flex">
<span>def <span class="ident">add_fields_to_resultant_dict</span></span>(<span>self, htmlurl, paper, paper_number, pdfurl, dict_for_paper)</span>
</code></dt>
<dd>
<div class="desc"><p>Writes urls to dictionary</p>
<p>:param htmlurl: list containing html urls for the paper</p>
<p>:param paper: python dictionary of the paper</p>
<p>:param paper_number: paper number to log</p>
<p>:param pdfurl: list containing pdf urls for the paper</p>
<p>:param dict_for_paper: python dictionary to write the urls to</p>
<p>:return: dict_for_paper</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_fields_to_resultant_dict(self, htmlurl, paper, paper_number, pdfurl, dict_for_paper):
    &#34;&#34;&#34;
    Writes urls to dictionary

    :param htmlurl: list containing html urls for the paper

    :param paper: python dictionary of the paper

    :param paper_number: paper number to log

    :param pdfurl: list containing pdf urls for the paper

    :param dict_for_paper: python dictionary to write the urls to

    :return: dict_for_paper
    &#34;&#34;&#34;
    import logging
    try:
        dict_for_paper[self.HTMLLINKS] = htmlurl[0]
    except:
        logging.warning(
            f&#34;html url not found for paper {paper_number}&#34;)
    try:
        dict_for_paper[&#34;abstract&#34;] = paper[&#34;abstractText&#34;]
    except:
        logging.warning(
            f&#34;Abstract not found for paper {paper_number}&#34;)

    try:
        dict_for_paper[&#34;Keywords&#34;] = paper[&#34;keywordList&#34;][&#34;keyword&#34;]
    except:
        logging.warning(
            f&#34;Keywords not found for paper {paper_number}&#34;)
    try:
        dict_for_paper[self.PDFLINKS] = pdfurl[0]
    except:
        logging.warning(
            f&#34;pdf url not found for paper {paper_number}&#34;)
    try:
        dict_for_paper[self.JOURNALTITLE] = paper[&#34;journalInfo&#34;][&#34;journal&#34;][self.TITLE]
    except:
        logging.warning(
            f&#34;journalInfo not found for paper {paper_number}&#34;)
    try:
        dict_for_paper[self.AUTHORINFO
                       ] = paper[&#34;authorList&#34;][&#34;author&#34;][0][&#39;fullName&#39;]
    except:
        logging.warning(
            f&#34;Author list not found for paper {paper_number}&#34;)
    try:
        dict_for_paper[self.TITLE] = paper[self.TITLE]
    except:
        logging.warning(
            f&#34;Title not found for paper {paper_number}&#34;)</code></pre>
</details>
</dd>
<dt id="pygetpapers.pygetpapers.pygetpapers.apipaperdownload"><code class="name flex">
<span>def <span class="ident">apipaperdownload</span></span>(<span>self, query, size, onlymakejson=False, getpdf=False, makecsv=False, makexml=False, references=False, citations=False, supplementaryFiles=False, synonym=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Downloads and writes papers along with the metadata for the given query</p>
<p>:param query: Query to download papers for</p>
<p>:param size: Number of papers to be downloaded</p>
<p>:param *onlymakejson(bool): whether to only write the json files</p>
<p>:param *getpdf(bool): whether to make pdf files</p>
<p>:param *makecsv(bool): whether to make csv files</p>
<p>:param *makexml(bool):whether to make xml files</p>
<p>:param *references: Source to get the references from</p>
<p>:param *citations: Source to get the citations from</p>
<p>:param *supplementaryFiles(bool): whether to write supplementary files</p>
<p>:param *synonym(bool): whether to also get files with query as the synonym of the given query</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def apipaperdownload(self, query, size, onlymakejson=False, getpdf=False, makecsv=False, makexml=False,
                     references=False, citations=False, supplementaryFiles=False, synonym=True):
    &#34;&#34;&#34;
    Downloads and writes papers along with the metadata for the given query

    :param query: Query to download papers for

    :param size: Number of papers to be downloaded

    :param *onlymakejson(bool): whether to only write the json files

    :param *getpdf(bool): whether to make pdf files

    :param *makecsv(bool): whether to make csv files

    :param *makexml(bool):whether to make xml files

    :param *references: Source to get the references from

    :param *citations: Source to get the citations from

    :param *supplementaryFiles(bool): whether to write supplementary files

    :param *synonym(bool): whether to also get files with query as the synonym of the given query
    &#34;&#34;&#34;
    import os
    query_result = self.europe_pmc.europepmc(query, size, synonym=synonym)
    self.makecsv(query_result, makecsv=makecsv)

    if not (onlymakejson):
        read_json = super().readjsondata(os.path.join(
            str(os.getcwd()), &#39;eupmc_results.json&#39;))
        self.makexmlfiles(read_json, getpdf=getpdf, makecsv=makecsv, makexml=makexml,
                          references=references, citations=citations, supplementaryFiles=supplementaryFiles)</code></pre>
</details>
</dd>
<dt id="pygetpapers.pygetpapers.pygetpapers.get_urls_to_write_to"><code class="name flex">
<span>def <span class="ident">get_urls_to_write_to</span></span>(<span>self, pmcid)</span>
</code></dt>
<dd>
<div class="desc"><p>:param pmcid: pmcid to write the urls for</p>
<p>:return: tuple containing urls where files for the fulltext will be written</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_urls_to_write_to(self, pmcid):
    &#34;&#34;&#34;
    :param pmcid: pmcid to write the urls for

    :return: tuple containing urls where files for the fulltext will be written
    &#34;&#34;&#34;
    import os
    destination_url = os.path.join(
        str(os.getcwd()), pmcid, &#34;fulltext.xml&#34;)
    directory_url = os.path.join(str(os.getcwd()), pmcid)
    jsonurl = os.path.join(
        str(os.getcwd()), pmcid, &#34;eupmc_result.json&#34;)
    referenceurl = os.path.join(
        str(os.getcwd()), pmcid, &#34;references.xml&#34;)
    citationurl = os.path.join(
        str(os.getcwd()), pmcid, &#34;citation.xml&#34;)
    supplementaryfilesurl = os.path.join(
        str(os.getcwd()), pmcid, &#34;supplementaryfiles.zip&#34;)
    return citationurl, destination_url, directory_url, jsonurl, referenceurl, supplementaryfilesurl</code></pre>
</details>
</dd>
<dt id="pygetpapers.pygetpapers.pygetpapers.getcitations"><code class="name flex">
<span>def <span class="ident">getcitations</span></span>(<span>self, pmcid, source)</span>
</code></dt>
<dd>
<div class="desc"><p>Gets citations for the paper of pmcid</p>
<p>:param pmcid: pmcid to get the citations</p>
<p>:param source: source to get the citations from</p>
<p>:return: citations xml</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def getcitations(self, pmcid, source):
    &#34;&#34;&#34;
    Gets citations for the paper of pmcid

    :param pmcid: pmcid to get the citations

    :param source: source to get the citations from

    :return: citations xml

    &#34;&#34;&#34;
    import requests
    r = requests.get(
        f&#34;https://www.ebi.ac.uk/europepmc/webservices/rest/{source}/{pmcid}/citations?page=1&amp;pageSize=1000&amp;format=xml&#34;)
    return r.content</code></pre>
</details>
</dd>
<dt id="pygetpapers.pygetpapers.pygetpapers.getreferences"><code class="name flex">
<span>def <span class="ident">getreferences</span></span>(<span>self, pmcid, source)</span>
</code></dt>
<dd>
<div class="desc"><p>Gets references for the paper of pmcid</p>
<p>:param pmcid: pmcid to get the references</p>
<p>:param source: source to get the references from</p>
<p>:return: references xml</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def getreferences(self, pmcid, source):
    &#34;&#34;&#34;
    Gets references for the paper of pmcid

    :param pmcid: pmcid to get the references

    :param source: source to get the references from

    :return: references xml

    &#34;&#34;&#34;
    import requests
    r = requests.get(
        f&#34;https://www.ebi.ac.uk/europepmc/webservices/rest/{source}/{pmcid}/references?page=1&amp;pageSize=1000&amp;format=xml&#34;)
    return r.content</code></pre>
</details>
</dd>
<dt id="pygetpapers.pygetpapers.pygetpapers.getsupplementaryfiles"><code class="name flex">
<span>def <span class="ident">getsupplementaryfiles</span></span>(<span>self, pmcid, directory_url, destination_url)</span>
</code></dt>
<dd>
<div class="desc"><p>Downloads the supplemetary marks for the paper having pmcid</p>
<p>:param pmcid: pmcid to get the supplementary files</p>
<p>:param directory_url: directory containg destination</p>
<p>:param destination_url: path to write the supplementary files to</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def getsupplementaryfiles(self, pmcid, directory_url, destination_url):
    &#34;&#34;&#34;
    Downloads the supplemetary marks for the paper having pmcid

    :param pmcid: pmcid to get the supplementary files

    :param directory_url: directory containg destination

    :param destination_url: path to write the supplementary files to
    &#34;&#34;&#34;
    import requests
    import os
    import logging
    r = requests.get(
        f&#34;https://www.ebi.ac.uk/europepmc/webservices/rest/{pmcid}/supplementaryFiles&#34;, stream=True)
    if not os.path.isdir(directory_url):
        os.makedirs(directory_url)
    with open(destination_url, &#39;wb&#39;) as fd:
        for chunk in r.iter_content(chunk_size=128):
            fd.write(chunk)
    logging.debug(f&#34;Wrote supplementary files for {pmcid}&#34;)</code></pre>
</details>
</dd>
<dt id="pygetpapers.pygetpapers.pygetpapers.getxml"><code class="name flex">
<span>def <span class="ident">getxml</span></span>(<span>self, pmcid)</span>
</code></dt>
<dd>
<div class="desc"><p>Makes a query for the pmcid xml to eupmc rest.</p>
<p>:param pmcid: pmcid of the paper to query for</p>
<p>:return: query result</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def getxml(self, pmcid):
    &#34;&#34;&#34;
    Makes a query for the pmcid xml to eupmc rest.

    :param pmcid: pmcid of the paper to query for

    :return: query result
    &#34;&#34;&#34;
    import requests
    r = requests.get(
        f&#34;https://www.ebi.ac.uk/europepmc/webservices/rest/{pmcid}/fullTextXML&#34;)
    return r.content</code></pre>
</details>
</dd>
<dt id="pygetpapers.pygetpapers.pygetpapers.handlecli"><code class="name flex">
<span>def <span class="ident">handlecli</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Handles the command line interface using argparse</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def handlecli(self):
    &#34;&#34;&#34;
    Handles the command line interface using argparse
    &#34;&#34;&#34;
    version = &#34;0.0.3.2&#34;
    import argparse
    import os
    import logging
    import sys
    from time import gmtime, strftime
    default_path = strftime(&#34;%Y_%m_%d_%H_%M_%S&#34;, gmtime())
    parser = argparse.ArgumentParser(
        description=f&#34;Welcome to Pygetpapers version {version}. -h or --help for help&#34;)
    parser.add_argument(&#34;-v&#34;, &#34;--version&#34;,
                        default=False, action=&#34;store_true&#34;, help=&#34;output the version number&#34;)
    parser.add_argument(&#34;-q&#34;, &#34;--query&#34;,
                        type=str, default=False,
                        help=&#34;query string transmitted to repository API. Eg. \&#34;Artificial Intelligence\&#34; or \&#34;Plant Parts\&#34;. To escape special characters within the quotes, use backslash. Incase of nested quotes, ensure that the initial quotes are double and the qutoes inside are single. For eg: `&#39;(LICENSE:\&#34;cc by\&#34; OR LICENSE:\&#34;cc-by\&#34;) AND METHODS:\&#34;transcriptome assembly\&#34;&#39; ` is wrong. We should instead use `\&#34;(LICENSE:&#39;cc by&#39; OR LICENSE:&#39;cc-by&#39;) AND METHODS:&#39;transcriptome assembly&#39;\&#34;` &#34;)

    parser.add_argument(&#34;-o&#34;, &#34;--output&#34;,
                        type=str, help=&#34;output directory (Default: Folder inside current working directory named )&#34;, default=os.path.join(os.getcwd(), default_path))
    parser.add_argument(&#34;-x&#34;, &#34;--xml&#34;, default=False, action=&#39;store_true&#39;,
                        help=&#34;download fulltext XMLs if available&#34;)
    parser.add_argument(&#34;-p&#34;, &#34;--pdf&#34;, default=False, action=&#39;store_true&#39;,
                        help=&#34;download fulltext PDFs if available&#34;)
    parser.add_argument(&#34;-s&#34;, &#34;--supp&#34;, default=False, action=&#39;store_true&#39;,
                        help=&#34;download supplementary files if available     &#34;)
    parser.add_argument(&#34;--references&#34;,
                        type=str, default=False,
                        help=&#34;Download references if available. Requires source for references (AGR,CBA,CTX,ETH,HIR,MED,PAT,PMC,PPR).&#34;)
    parser.add_argument(&#34;-n&#34;, &#34;--noexecute&#34;, default=False, action=&#39;store_true&#39;,
                        help=&#34;report how many results match the query, but don&#39;t actually download anything&#34;)

    parser.add_argument(&#34;--citations&#34;, type=str, default=False,
                        help=&#34;Download citations if available. Requires source for citations (AGR,CBA,CTX,ETH,HIR,MED,PAT,PMC,PPR).&#34;)
    parser.add_argument(&#34;-l&#34;, &#39;--loglevel&#39;, default=&#34;info&#34;,
                        help=&#34;Provide logging level.  Example --log warning &lt;&lt;info,warning,debug,error,critical&gt;&gt;, default=&#39;info&#39;&#34;)
    parser.add_argument(&#34;-f&#34;, &#34;--logfile&#34;, default=False,
                        type=str,
                        help=&#34;save log to specified file in output directory as well as printing to terminal&#34;)
    parser.add_argument(&#34;-k&#34;, &#34;--limit&#34;, default=100,
                        type=int, help=&#34;maximum number of hits (default: 100)&#34;)

    parser.add_argument(&#39;-r&#39;, &#34;--restart&#34;, default=False,
                        type=str,
                        help=&#34;Reads the json and makes the xml files. Takes the path to the json as the input&#34;)

    parser.add_argument(&#34;-u&#34;, &#34;--update&#34;, default=False,
                        type=str,
                        help=&#34;Updates the corpus by downloading new papers. Takes the path of metadata json file of the orignal corpus as the input. Requires -k or --limit (If not provided, default will be used) and -q or --query (must be provided) to be given. Takes the path to the json as the input.&#34;)
    parser.add_argument(&#34;--onlyquery&#34;, action=&#39;store_true&#39;,
                        help=&#34;Saves json file containing the result of the query in storage. The json file can be given to --restart to download the papers later.&#34;)
    parser.add_argument(&#34;-c&#34;, &#34;--makecsv&#34;, default=False, action=&#39;store_true&#39;,
                        help=&#34;Stores the per-document metadata as csv. Works only with --api method.&#34;)
    parser.add_argument(&#34;--synonym&#34;, default=False, action=&#39;store_true&#39;,
                        help=&#34;Results contain synonyms as well.&#34;)
    if len(sys.argv) == 1:
        parser.print_help(sys.stderr)
        sys.exit()
    args = parser.parse_args()

    if os.path.exists(args.output):
        os.chdir(args.output)
    else:
        os.makedirs(args.output)
        os.chdir(args.output)
    levels = {
        &#39;critical&#39;: logging.CRITICAL,
        &#39;error&#39;: logging.ERROR,
        &#39;warn&#39;: logging.WARNING,
        &#39;warning&#39;: logging.WARNING,
        &#39;info&#39;: logging.INFO,
        &#39;debug&#39;: logging.DEBUG
    }
    level = levels.get(args.loglevel.lower())
    if args.logfile:
        logging.basicConfig(filename=args.logfile,
                            level=level, filemode=&#39;w&#39;)
        console = logging.StreamHandler()

        console.setLevel(level)
        formatter = logging.Formatter(&#39;%(levelname)s: %(message)s&#39;)
        # tell the handler to use this format
        console.setFormatter(formatter)
        logging.getLogger().addHandler(console)
        logging.info(f&#39;Making log file at {args.logfile}&#39;)

    else:
        logging.basicConfig(
            level=level, format=&#39;%(levelname)s: %(message)s&#39;)

    if not args.query:
        logging.warning(&#39;Please specify a query&#39;)
        sys.exit(1)

    if args.noexecute:
        self.noexecute(args.query, synonym=args.synonym)
    elif args.version:
        logging.info(version)
    elif args.restart:
        import os
        import logging
        read_json = super().readjsondata(args.restart)
        os.chdir(os.path.dirname(args.restart))
        self.makexmlfiles(read_json, getpdf=args.pdf, makecsv=args.makecsv, makexml=args.xml,
                          references=args.references, citations=args.citations, supplementaryFiles=args.supp)
    elif args.update:
        read_json = super().readjsondata(args.update)
        os.chdir(os.path.dirname(args.update))
        self.updatecorpus(args.query, read_json, args.limit, getpdf=args.pdf,
                          makecsv=args.makecsv, makexml=args.xml, references=args.references,
                          citations=args.citations, supplementaryFiles=args.supp, synonym=args.synonym)
    else:
        if args.query:
            self.apipaperdownload(args.query, args.limit,
                                  onlymakejson=args.onlyquery, getpdf=args.pdf, makecsv=args.makecsv,
                                  makexml=args.xml, references=args.references, citations=args.citations,
                                  supplementaryFiles=args.supp, synonym=args.synonym)</code></pre>
</details>
</dd>
<dt id="pygetpapers.pygetpapers.pygetpapers.make_citations"><code class="name flex">
<span>def <span class="ident">make_citations</span></span>(<span>self, source, citationurl, directory_url, paperid)</span>
</code></dt>
<dd>
<div class="desc"><p>Downloads the citations for the paper with pmcid (paperid) to citation url</p>
<p>:param source: source to get the citations from</p>
<p>:param citationurl: path to write the citations to</p>
<p>:param directory_url: directory containing citationurl</p>
<p>:param paperid: pmc id of the paper</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def make_citations(self, source, citationurl, directory_url, paperid):
    &#39;&#39;&#39;
    Downloads the citations for the paper with pmcid (paperid) to citation url

    :param source: source to get the citations from

    :param citationurl: path to write the citations to

    :param directory_url: directory containing citationurl

    :param paperid: pmc id of the paper
    &#39;&#39;&#39;
    getcitations = self.getcitations(
        paperid, source)
    self.writexml(directory_url, citationurl, getcitations)</code></pre>
</details>
</dd>
<dt id="pygetpapers.pygetpapers.pygetpapers.make_csv"><code class="name flex">
<span>def <span class="ident">make_csv</span></span>(<span>self, dict_to_write, pmcid)</span>
</code></dt>
<dd>
<div class="desc"><p>Makes csv file for the dict_to_write (python dictionary for the fulltext).</p>
<p>:param dict_to_write: Python dictionary to write the csv from</p>
<p>:param pmcid: pmcid of the paper</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def make_csv(self, dict_to_write, pmcid):
    &#34;&#34;&#34;
    Makes csv file for the dict_to_write (python dictionary for the fulltext).

    :param dict_to_write: Python dictionary to write the csv from

    :param pmcid: pmcid of the paper

    &#34;&#34;&#34;
    import pandas as pd
    import os
    df = pd.Series(dict_to_write).to_frame(
        &#39;Info_By_EuropePMC_Api&#39;)
    df.to_csv(os.path.join(
        str(os.getcwd()), pmcid, &#34;fulltext.csv&#34;))</code></pre>
</details>
</dd>
<dt id="pygetpapers.pygetpapers.pygetpapers.make_initial_columns_for_paper_dict"><code class="name flex">
<span>def <span class="ident">make_initial_columns_for_paper_dict</span></span>(<span>self, pmcid, resultant_dict)</span>
</code></dt>
<dd>
<div class="desc"><p>:param pmcid: pmcid of the paper for which fields will be created
:param resultant_dict: dict in which the fields will be created
:return: dict with the initial fields created for pmcid</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def make_initial_columns_for_paper_dict(self, pmcid, resultant_dict):
    &#34;&#34;&#34;
    :param pmcid: pmcid of the paper for which fields will be created
    :param resultant_dict: dict in which the fields will be created
    :return: dict with the initial fields created for pmcid
    &#34;&#34;&#34;
    resultant_dict[pmcid] = {}
    resultant_dict[pmcid][&#34;downloaded&#34;] = False
    resultant_dict[pmcid][&#34;pdfdownloaded&#34;] = False
    resultant_dict[pmcid][&#34;jsondownloaded&#34;] = False
    resultant_dict[pmcid][&#34;csvmade&#34;] = False
    return resultant_dict</code></pre>
</details>
</dd>
<dt id="pygetpapers.pygetpapers.pygetpapers.make_references"><code class="name flex">
<span>def <span class="ident">make_references</span></span>(<span>self, directory_url, paperid, source, referenceurl)</span>
</code></dt>
<dd>
<div class="desc"><p>Downloads the references for the paper with pmcid (paperid) to reference url</p>
<p>:param directory_url: directory containing referenceurl</p>
<p>:param paperid:
pmc id of the paper</p>
<p>:param source: source to get the citations from</p>
<p>:param referenceurl: path to write the references to</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def make_references(self, directory_url, paperid, source, referenceurl):
    &#39;&#39;&#39;
    Downloads the references for the paper with pmcid (paperid) to reference url

    :param directory_url: directory containing referenceurl

    :param paperid:  pmc id of the paper

    :param source: source to get the citations from

    :param referenceurl: path to write the references to
    &#39;&#39;&#39;
    getreferences = self.getreferences(
        paperid, source)
    self.writexml(directory_url, referenceurl, getreferences)</code></pre>
</details>
</dd>
<dt id="pygetpapers.pygetpapers.pygetpapers.makecsv"><code class="name flex">
<span>def <span class="ident">makecsv</span></span>(<span>self, searchvariable, makecsv=False, update=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Writes the json and *csv for searchvaraible dict</p>
<p>:param searchvariable(dict): Python dictionary which contains all the research papers (given by europe_pmc.europepmc))</p>
<p>:param makecsv(bool): whether to make csv files</p>
<p>:param update(dict): if provided, will add the research papers to the searchvariable dict</p>
<p>:return: searchvariable</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def makecsv(self, searchvariable, makecsv=False, update=False):
    &#34;&#34;&#34;
    Writes the json and *csv for searchvaraible dict

    :param searchvariable(dict): Python dictionary which contains all the research papers (given by europe_pmc.europepmc))

    :param makecsv(bool): whether to make csv files

    :param update(dict): if provided, will add the research papers to the searchvariable dict

    :return: searchvariable
    &#34;&#34;&#34;
    import pandas as pd
    import json
    import os
    import logging
    resultant_dict = {}
    for paper_number, papers in enumerate(searchvariable):
        output_dict = json.loads(json.dumps(papers))
        for paper in output_dict:
            if self.PMCID in paper:
                paper_number += 1
                htmlurl, paperpmcid, pdfurl, resultant_dict = self.write_meta_data_for_paper(
                    paper, paper_number, resultant_dict)
                self.add_fields_to_resultant_dict(
                    htmlurl, paper, paper_number, pdfurl, resultant_dict[paperpmcid])
                logging.debug(
                    f&#39;Wrote Meta Data to a dictionary that will be written to all the chosen metadata file formats for paper {paperpmcid}&#39;)
    if update:
        resultant_dict.update(update)
    directory_url = os.path.join(
        str(os.getcwd()))
    jsonurl = os.path.join(
        str(os.getcwd()), &#39;eupmc_results.json&#39;)
    super().check_or_make_directory(directory_url)
    self.makejson(jsonurl, resultant_dict)
    resultant_dict_for_csv = super().make_dict_for_csv(resultant_dict)
    df = pd.DataFrame.from_dict(resultant_dict_for_csv, )
    df_transposed = df.T
    if makecsv:
        super().write_or_append_to_csv(df_transposed)
    return searchvariable</code></pre>
</details>
</dd>
<dt id="pygetpapers.pygetpapers.pygetpapers.makexmlfiles"><code class="name flex">
<span>def <span class="ident">makexmlfiles</span></span>(<span>self, final_xml_dict, getpdf=False, makecsv=False, makexml=False, references=False, citations=False, supplementaryFiles=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Writes the <em>pdf,</em>csv,<em>xml,</em>references,<em>citations,</em>supplementaryFiles for the individual papers</p>
<p>:param final_xml_dict: Python dictionary containg all the papers</p>
<p>:param getpdf(bool): whether to make pdfs</p>
<p>:param makecsv(bool): whether to make csv for the metadata</p>
<p>:param makexml(bool): whether to make xml file for the paper</p>
<p>:param references(bool): whether to download references</p>
<p>:param citations(bool): whether to download citations</p>
<p>:param supplementaryFiles(bool): whether to download supplementary files</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def makexmlfiles(self, final_xml_dict, getpdf=False, makecsv=False, makexml=False, references=False,
                 citations=False, supplementaryFiles=False):
    &#34;&#34;&#34;
    Writes the *pdf,*csv,*xml,*references,*citations,*supplementaryFiles for the individual papers

    :param final_xml_dict: Python dictionary containg all the papers

    :param getpdf(bool): whether to make pdfs

    :param makecsv(bool): whether to make csv for the metadata

    :param makexml(bool): whether to make xml file for the paper

    :param references(bool): whether to download references

    :param citations(bool): whether to download citations

    :param supplementaryFiles(bool): whether to download supplementary files

    &#34;&#34;&#34;
    import logging
    import os
    import time
    if makexml:
        super().log_making_xml()
    paper_number = 0
    for paper in final_xml_dict:
        start = time.time()
        paper_number += 1
        pmcid = paper
        tree = self.getxml(pmcid)
        citationurl, destination_url, directory_url, jsonurl, referenceurl, supplementaryfilesurl = self.get_urls_to_write_to(
            pmcid)
        paperdict = final_xml_dict[paper]
        paperid = paperdict[&#34;full&#34;][&#34;id&#34;]
        if references:
            self.make_references(directory_url, paperid,
                                 references, referenceurl)
            logging.info(f&#34;Made references for {pmcid}&#34;)
        if citations:
            self.make_citations(citations, citationurl,
                                directory_url, paperid)
            logging.info(f&#34;Made Citations for {pmcid}&#34;)
        if supplementaryFiles:
            self.getsupplementaryfiles(
                paperid, directory_url, supplementaryfilesurl)
            logging.info(f&#34;Made Supplementary files for {pmcid}&#34;)
        if not os.path.isdir(directory_url):
            os.makedirs(directory_url)
        condition_to_down, condition_to_download_csv, condition_to_download_json, condition_to_download_pdf = super().conditions_to_download(
            paperdict)
        if condition_to_down:
            if makexml:
                super().writexml(directory_url, destination_url, tree)
                logging.info(f&#34;*/Wrote xml for {pmcid}/&#34;)
                paperdict[&#34;downloaded&#34;] = True
        if condition_to_download_pdf:
            if getpdf:
                pdf_destination = os.path.join(
                    str(os.getcwd()), pmcid, &#34;fulltext.pdf&#34;)
                if &#34;pdflinks&#34; in paperdict:
                    if len(paperdict[&#34;pdflinks&#34;]) &gt; 0:
                        super().writepdf(
                            paperdict[&#34;pdflinks&#34;], pdf_destination)
                        paperdict[&#34;pdfdownloaded&#34;] = True
                        logging.info(f&#34;Wrote the pdf file for {pmcid}&#34;)
        dict_to_write = super().clean_dict_for_csv(paperdict)
        if condition_to_download_json:
            super().makejson(jsonurl, dict_to_write)
            paperdict[&#34;jsondownloaded&#34;] = True
        if condition_to_download_csv:
            if makecsv:
                self.make_csv(dict_to_write, pmcid)
                paperdict[&#34;csvmade&#34;] = True
        super().makejson(os.path.join(
            str(os.getcwd()), &#39;eupmc_results.json&#39;), final_xml_dict)
        stop = time.time()
        logging.debug(f&#34;Time elapsed: {stop - start}&#34;)
        logging.debug(f&#34;*/Updating the json*/\n&#34;)</code></pre>
</details>
</dd>
<dt id="pygetpapers.pygetpapers.pygetpapers.noexecute"><code class="name flex">
<span>def <span class="ident">noexecute</span></span>(<span>self, query, synonym=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Tells how many hits found for the query</p>
<p>:param query:</p>
<p>:param synonym:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def noexecute(self, query, synonym=True):
    &#34;&#34;&#34;
    Tells how many hits found for the query

    :param query:

    :param synonym:
    &#34;&#34;&#34;
    import logging
    builtqueryparams = super().buildquery(
        &#39;*&#39;, 25, query, synonym=synonym)
    HEADERS = &#39;headers&#39;
    PAYLOAD = &#39;payload&#39;
    result = super().postquery(
        builtqueryparams[HEADERS], builtqueryparams[PAYLOAD])
    totalhits = result[&#39;responseWrapper&#39;][&#39;hitCount&#39;]
    logging.info(f&#39;Total number of hits for the query are {totalhits}&#39;)</code></pre>
</details>
</dd>
<dt id="pygetpapers.pygetpapers.pygetpapers.updatecorpus"><code class="name flex">
<span>def <span class="ident">updatecorpus</span></span>(<span>self, query, original_json, size, onlymakejson=False, getpdf=False, makecsv=False, makexml=False, references=False, citations=False, supplementaryFiles=False, synonym=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Updates the corpus with new papers</p>
<p>:param query(str):
Query to download papers for</p>
<p>:param original_json: Json of the original corpus in the form of python dictionary</p>
<p>:param size(int): Number of new papers to download</p>
<p>:param *onlymakejson(bool): whether to only write json files</p>
<p>:param *getpdf(bool): whether to make pdf files</p>
<p>:param *makecsv(bool): whether to make csv files</p>
<p>:param *makexml(bool): whether to make xml files</p>
<p>:param *references: Source to get the references from</p>
<p>:param *citations: Source to get the citations from</p>
<p>:param *supplementaryFiles(bool): whether to write supplementary files</p>
<p>:param *synonym(bool): whether to also get files with query as the synonym of the given query</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def updatecorpus(self, query, original_json, size, onlymakejson=False, getpdf=False, makecsv=False, makexml=False,
                 references=False, citations=False, supplementaryFiles=False, synonym=True):
    &#34;&#34;&#34;
    Updates the corpus with new papers

    :param query(str):  Query to download papers for

    :param original_json: Json of the original corpus in the form of python dictionary

    :param size(int): Number of new papers to download

    :param *onlymakejson(bool): whether to only write json files

    :param *getpdf(bool): whether to make pdf files

    :param *makecsv(bool): whether to make csv files

    :param *makexml(bool): whether to make xml files

    :param *references: Source to get the references from

    :param *citations: Source to get the citations from

    :param *supplementaryFiles(bool): whether to write supplementary files

    :param *synonym(bool): whether to also get files with query as the synonym of the given query

    &#34;&#34;&#34;
    import os
    query_result = self.europe_pmc.europepmc(
        query, size, update=original_json, synonym=synonym)
    self.makecsv(query_result, makecsv=makecsv,
                 update=original_json)
    if not onlymakejson:
        read_json = super().readjsondata(os.path.join(
            str(os.getcwd()), &#39;eupmc_results.json&#39;))
        self.makexmlfiles(read_json, getpdf=getpdf,
                          makecsv=makecsv, makexml=makexml, references=references, citations=citations,
                          supplementaryFiles=supplementaryFiles)</code></pre>
</details>
</dd>
<dt id="pygetpapers.pygetpapers.pygetpapers.write_meta_data_for_paper"><code class="name flex">
<span>def <span class="ident">write_meta_data_for_paper</span></span>(<span>self, paper, paper_number, resultant_dict)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds pdf and html url as well as makes the paper key in resultant_dict</p>
<p>:param paper: python dictionary for the paper</p>
<p>:param paper_number: paper number to log</p>
<p>:param resultant_dict: dictionary to add paper as well as pdf,html url to</p>
<p>:return: (htmlurl, paperpmcid, pdfurl, resultant_dict)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def write_meta_data_for_paper(self, paper, paper_number, resultant_dict):
    &#34;&#34;&#34;
    Adds pdf and html url as well as makes the paper key in resultant_dict

    :param paper: python dictionary for the paper

    :param paper_number: paper number to log

    :param resultant_dict: dictionary to add paper as well as pdf,html url to

    :return: (htmlurl, paperpmcid, pdfurl, resultant_dict)
    &#34;&#34;&#34;
    import logging
    logging.debug(
        f&#34;Reading Query Result for paper {paper_number}&#34;)
    pdfurl = []
    htmlurl = []
    for x in paper[&#34;fullTextUrlList&#34;][&#34;fullTextUrl&#34;]:
        if x[&#34;documentStyle&#34;] == &#34;pdf&#34; and x[&#34;availability&#34;] == &#34;Open access&#34;:
            pdfurl.append(x[&#34;url&#34;])

        if x[&#34;documentStyle&#34;] == &#34;html&#34; and x[&#34;availability&#34;] == &#34;Open access&#34;:
            htmlurl.append(x[&#34;url&#34;])
    paperpmcid = paper[&#34;pmcid&#34;]
    resultant_dict = self.make_initial_columns_for_paper_dict(
        paperpmcid, resultant_dict)
    resultant_dict[paperpmcid][&#34;full&#34;] = paper
    return htmlurl, paperpmcid, pdfurl, resultant_dict</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="pygetpapers.download_tools.download_tools" href="download_tools.html#pygetpapers.download_tools.download_tools">download_tools</a></b></code>:
<ul class="hlist">
<li><code><a title="pygetpapers.download_tools.download_tools.buildquery" href="download_tools.html#pygetpapers.download_tools.download_tools.buildquery">buildquery</a></code></li>
<li><code><a title="pygetpapers.download_tools.download_tools.check_or_make_directory" href="download_tools.html#pygetpapers.download_tools.download_tools.check_or_make_directory">check_or_make_directory</a></code></li>
<li><code><a title="pygetpapers.download_tools.download_tools.clean_dict_for_csv" href="download_tools.html#pygetpapers.download_tools.download_tools.clean_dict_for_csv">clean_dict_for_csv</a></code></li>
<li><code><a title="pygetpapers.download_tools.download_tools.conditions_to_download" href="download_tools.html#pygetpapers.download_tools.download_tools.conditions_to_download">conditions_to_download</a></code></li>
<li><code><a title="pygetpapers.download_tools.download_tools.log_making_xml" href="download_tools.html#pygetpapers.download_tools.download_tools.log_making_xml">log_making_xml</a></code></li>
<li><code><a title="pygetpapers.download_tools.download_tools.make_dict_for_csv" href="download_tools.html#pygetpapers.download_tools.download_tools.make_dict_for_csv">make_dict_for_csv</a></code></li>
<li><code><a title="pygetpapers.download_tools.download_tools.makejson" href="download_tools.html#pygetpapers.download_tools.download_tools.makejson">makejson</a></code></li>
<li><code><a title="pygetpapers.download_tools.download_tools.postquery" href="download_tools.html#pygetpapers.download_tools.download_tools.postquery">postquery</a></code></li>
<li><code><a title="pygetpapers.download_tools.download_tools.readjsondata" href="download_tools.html#pygetpapers.download_tools.download_tools.readjsondata">readjsondata</a></code></li>
<li><code><a title="pygetpapers.download_tools.download_tools.write_or_append_to_csv" href="download_tools.html#pygetpapers.download_tools.download_tools.write_or_append_to_csv">write_or_append_to_csv</a></code></li>
<li><code><a title="pygetpapers.download_tools.download_tools.writepdf" href="download_tools.html#pygetpapers.download_tools.download_tools.writepdf">writepdf</a></code></li>
<li><code><a title="pygetpapers.download_tools.download_tools.writexml" href="download_tools.html#pygetpapers.download_tools.download_tools.writexml">writexml</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="pygetpapers" href="index.html">pygetpapers</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="pygetpapers.pygetpapers.demo" href="#pygetpapers.pygetpapers.demo">demo</a></code></li>
<li><code><a title="pygetpapers.pygetpapers.main" href="#pygetpapers.pygetpapers.main">main</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="pygetpapers.pygetpapers.pygetpapers" href="#pygetpapers.pygetpapers.pygetpapers">pygetpapers</a></code></h4>
<ul class="">
<li><code><a title="pygetpapers.pygetpapers.pygetpapers.add_fields_to_resultant_dict" href="#pygetpapers.pygetpapers.pygetpapers.add_fields_to_resultant_dict">add_fields_to_resultant_dict</a></code></li>
<li><code><a title="pygetpapers.pygetpapers.pygetpapers.apipaperdownload" href="#pygetpapers.pygetpapers.pygetpapers.apipaperdownload">apipaperdownload</a></code></li>
<li><code><a title="pygetpapers.pygetpapers.pygetpapers.get_urls_to_write_to" href="#pygetpapers.pygetpapers.pygetpapers.get_urls_to_write_to">get_urls_to_write_to</a></code></li>
<li><code><a title="pygetpapers.pygetpapers.pygetpapers.getcitations" href="#pygetpapers.pygetpapers.pygetpapers.getcitations">getcitations</a></code></li>
<li><code><a title="pygetpapers.pygetpapers.pygetpapers.getreferences" href="#pygetpapers.pygetpapers.pygetpapers.getreferences">getreferences</a></code></li>
<li><code><a title="pygetpapers.pygetpapers.pygetpapers.getsupplementaryfiles" href="#pygetpapers.pygetpapers.pygetpapers.getsupplementaryfiles">getsupplementaryfiles</a></code></li>
<li><code><a title="pygetpapers.pygetpapers.pygetpapers.getxml" href="#pygetpapers.pygetpapers.pygetpapers.getxml">getxml</a></code></li>
<li><code><a title="pygetpapers.pygetpapers.pygetpapers.handlecli" href="#pygetpapers.pygetpapers.pygetpapers.handlecli">handlecli</a></code></li>
<li><code><a title="pygetpapers.pygetpapers.pygetpapers.make_citations" href="#pygetpapers.pygetpapers.pygetpapers.make_citations">make_citations</a></code></li>
<li><code><a title="pygetpapers.pygetpapers.pygetpapers.make_csv" href="#pygetpapers.pygetpapers.pygetpapers.make_csv">make_csv</a></code></li>
<li><code><a title="pygetpapers.pygetpapers.pygetpapers.make_initial_columns_for_paper_dict" href="#pygetpapers.pygetpapers.pygetpapers.make_initial_columns_for_paper_dict">make_initial_columns_for_paper_dict</a></code></li>
<li><code><a title="pygetpapers.pygetpapers.pygetpapers.make_references" href="#pygetpapers.pygetpapers.pygetpapers.make_references">make_references</a></code></li>
<li><code><a title="pygetpapers.pygetpapers.pygetpapers.makecsv" href="#pygetpapers.pygetpapers.pygetpapers.makecsv">makecsv</a></code></li>
<li><code><a title="pygetpapers.pygetpapers.pygetpapers.makexmlfiles" href="#pygetpapers.pygetpapers.pygetpapers.makexmlfiles">makexmlfiles</a></code></li>
<li><code><a title="pygetpapers.pygetpapers.pygetpapers.noexecute" href="#pygetpapers.pygetpapers.pygetpapers.noexecute">noexecute</a></code></li>
<li><code><a title="pygetpapers.pygetpapers.pygetpapers.updatecorpus" href="#pygetpapers.pygetpapers.pygetpapers.updatecorpus">updatecorpus</a></code></li>
<li><code><a title="pygetpapers.pygetpapers.pygetpapers.write_meta_data_for_paper" href="#pygetpapers.pygetpapers.pygetpapers.write_meta_data_for_paper">write_meta_data_for_paper</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>