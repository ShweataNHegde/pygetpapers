<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN" "JATS-archivearticle1-mathml3.dtd"> 
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="review-article"><?properties open_access?><?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName JATS-journalpublishing1.dtd?><?SourceDTD.Version 1.2?><?ConverterInfo.XSLTName jp2nlmx2.xsl?><?ConverterInfo.Version 1?><front><journal-meta><journal-id journal-id-type="nlm-ta">Korean J Radiol</journal-id><journal-id journal-id-type="iso-abbrev">Korean J Radiol</journal-id><journal-id journal-id-type="publisher-id">KJR</journal-id><journal-title-group><journal-title>Korean Journal of Radiology</journal-title></journal-title-group><issn pub-type="ppub">1229-6929</issn><issn pub-type="epub">2005-8330</issn><publisher><publisher-name>The Korean Society of Radiology</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">7909857</article-id><article-id pub-id-type="pmid">33629545</article-id><article-id pub-id-type="doi">10.3348/kjr.2021.0048</article-id><article-categories><subj-group subj-group-type="heading"><subject>Technology, Experiment, and Physics</subject><subj-group subj-group-type="subheading"><subject>Review Article</subject></subj-group></subj-group></article-categories><title-group><article-title>Key Principles of Clinical Validation, Device Approval, and Insurance Coverage Decisions of Artificial Intelligence</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-1257-8315</contrib-id><name><surname>Park</surname><given-names>Seong Ho</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-6817-618X</contrib-id><name><surname>Choi</surname><given-names>Jaesoon</given-names></name><xref ref-type="aff" rid="A2">2</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-9793-6379</contrib-id><name><surname>Byeon</surname><given-names>Jeong-Sik</given-names></name><xref ref-type="aff" rid="A3">3</xref></contrib></contrib-group><aff id="A1"><label>1</label>Department of Radiology and Research Institute of Radiology, Asan Medical Center, University of Ulsan College of Medicine, Seoul, <country>Korea</country>.</aff><aff id="A2"><label>2</label>Department of Biomedical Engineering, Asan Medical Center, University of Ulsan College of Medicine, Seoul, <country>Korea</country>.</aff><aff id="A3"><label>3</label>Department of Gastroenterology, Asan Medical Center, University of Ulsan College of Medicine, Seoul, <country>Korea</country>.</aff><author-notes><corresp>Corresponding author: Seong Ho Park, MD, PhD, Department of Radiology and Research Institute of Radiology, University of Ulsan College of Medicine, Asan Medical Center, 88 Olympic-ro 43-gil, Songpa-gu, Seoul 05505, Korea. <email>seongho@amc.seoul.kr</email></corresp></author-notes><pub-date pub-type="ppub"><month>3</month><year>2021</year></pub-date><pub-date pub-type="epub"><day>10</day><month>2</month><year>2021</year></pub-date><volume>22</volume><issue>3</issue><fpage>442</fpage><lpage>453</lpage><history><date date-type="received"><day>15</day><month>1</month><year>2021</year></date><date date-type="rev-recd"><day>15</day><month>1</month><year>2021</year></date><date date-type="accepted"><day>15</day><month>1</month><year>2021</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2021 The Korean Society of Radiology</copyright-statement><copyright-year>2021</copyright-year><copyright-holder>The Korean Society of Radiology</copyright-holder><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/"><license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">http://creativecommons.org/licenses/by-nc/4.0/</ext-link>) which permits unrestricted non-commercial use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p></license></permissions><abstract><p>Artificial intelligence (AI) will likely affect various fields of medicine. This article aims to explain the fundamental principles of clinical validation, device approval, and insurance coverage decisions of AI algorithms for medical diagnosis and prediction. Discrimination accuracy of AI algorithms is often evaluated with the Dice similarity coefficient, sensitivity, specificity, and traditional or free-response receiver operating characteristic curves. Calibration accuracy should also be assessed, especially for algorithms that provide probabilities to users. As current AI algorithms have limited generalizability to real-world practice, clinical validation of AI should put it to proper external testing and assisting roles. External testing could adopt diagnostic case-control or diagnostic cohort designs. A diagnostic case-control study evaluates the technical validity/accuracy of AI while the latter tests the clinical validity/accuracy of AI in samples representing target patients in real-world clinical scenarios. Ultimate clinical validation of AI requires evaluations of its impact on patient outcomes, referred to as clinical utility, and for which randomized clinical trials are ideal. Device approval of AI is typically granted with proof of technical validity/accuracy and thus does not intend to directly indicate if AI is beneficial for patient care or if it improves patient outcomes. Neither can it categorically address the issue of limited generalizability of AI. After achieving device approval, it is up to medical professionals to determine if the approved AI algorithms are beneficial for real-world patient care. Insurance coverage decisions generally require a demonstration of clinical utility that the use of AI has improved patient outcomes.</p></abstract><kwd-group><kwd>Software validation</kwd><kwd>Device approval</kwd><kwd>Insurance coverage</kwd><kwd>Artificial intelligence</kwd></kwd-group><funding-group><award-group><funding-source><institution-wrap><institution>Korea Health Industry Development Institute</institution><institution-id institution-id-type="CrossRef">https://doi.org/10.13039/501100003710</institution-id></institution-wrap></funding-source><award-id>HI17C2410</award-id></award-group></funding-group></article-meta></front><body><sec sec-type="intro"><title>INTRODUCTION</title><p>Artificial intelligence (AI) technology is expected to be of substantial help in medicine by overcoming current limitations and developing innovative solutions and will likely have a great impact on healthcare in the future [<xref rid="B1" ref-type="bibr">1</xref><xref rid="B2" ref-type="bibr">2</xref>]. All pharmaceuticals and medical devices, including AI devices, must be subjected to a rigorous clinical validation process to ensure safety and efficacy prior to use on patients. There is a wide range of AI devices for use in healthcare, and the methods used for clinical validation vary according to their form and function. Most are classified as diagnostic devices, as they are algorithms used to assist with diagnosis, decision-making, and prediction, such as computer-aided detection (CADe), computer-aided diagnosis, or clinical decision support systems. As such, methods for their clinical validation resemble those for common diagnostic tests. In this article, we aim to explain the key principles of clinical validation, device approval, and insurance coverage decisions for AI algorithms in healthcare.</p></sec><sec><title>Performance Indicators of AI Algorithms</title><p>There are a variety of indicators that may be used to evaluate the performance of AI algorithms. Some are technical indicators with little medical relevance, and others apply only to specific situations. Therefore, instead of presenting a comprehensive list of all indicators, we have focused on frequently used indicators with high medical relevance.</p><sec><title>Dice Similarity Coefficient</title><p>The Dice similarity coefficient is used to evaluate AI algorithms that perform segmentation of organs or lesions on medical images [<xref rid="B3" ref-type="bibr">3</xref>]. Its definition is illustrated in <xref ref-type="fig" rid="F1">Figure 1</xref>. For example, if there is an AI algorithm that can display the area suspected of prostate cancer on prostate magnetic resonance imaging (MRI), its performance can be evaluated by measuring the degree of overlap between the pathologically confirmed cancerous region and the area identified as cancer by the algorithm. There are several other coefficients similar to the Dice similarity coefficient.</p></sec><sec><title>Sensitivity, Specificity, Receiver Operating Characteristic Curve</title><p>As shown in <xref ref-type="fig" rid="F2">Figure 2</xref>, if an AI algorithm presents a binary result (e.g., presence vs. absence of a disease), its performance can be described, as in general diagnostic tests, in terms of sensitivity = true positive/(true positive + false negative), i.e., the proportion of subjects identified as positive by the AI out of all disease-positive subjects, and specificity = true negative/(false positive + true negative), i.e., the proportion of subjects identified as negative by the AI out of all disease-negative subjects. Even though the result an AI algorithm gives is presented as a binary classification, it is preceded by the process of outputting the result as a continuous number (for example, a decimal range between 0 and 1 as in probability). A threshold is then applied to convert it into a binary result. The sensitivity and specificity of the AI algorithm vary depending on how the threshold is set. If the threshold is set high, sensitivity decreases and specificity increases. If the threshold is set low, the sensitivity increases and the specificity decreases. A receiver operating characteristic (ROC) curve is a graph drawn by plotting the sensitivity on the y-axis and 1 - specificity on the x-axis, while varying the threshold value (<xref ref-type="fig" rid="F3">Fig. 3</xref>) [<xref rid="B4" ref-type="bibr">4</xref>]. The value of the area under the curve (AUC) or area under the ROC (AUROC) curve is the mean sensitivity or specificity for all possible threshold values. Its maximum value is 1. In theory, the higher the value, the higher the diagnostic accuracy. Interpretations should be made carefully, however, because a higher AUROC value of an AI algorithm is not necessarily equivalent to higher performance of the AI in practice. Given that a particular threshold value is required when using an AI algorithm in practice, the sensitivity and specificity values for the given threshold, not the mean AUROC value, are the algorithm's actual measures of performance. The AUROC value is merely the mean sensitivity or specificity value. For further details, see the relevant literature [<xref rid="B2" ref-type="bibr">2</xref><xref rid="B5" ref-type="bibr">5</xref><xref rid="B6" ref-type="bibr">6</xref>].</p></sec><sec><title>Free-Response ROC Curve</title><p>The free-response ROC (FROC) curve is used to evaluate the performance of AI algorithms with a CADe function, such as those for detecting colonic polyps on colonoscopy images. The AI algorithm output is correct when both the presence of a lesion and the localization of the lesion site are proven correct. When the AI algorithm for detecting colonic polyps indicates there is a polyp in a patient with colonic polyps, its diagnosis is correct only when it also detects the correct lesion site. If it fails to detect a polyp in an area where there is one and indicates there is a polyp in an area where there is none, it has produced both false-negative and false-positive results. In diagnostic tasks where a CADe-enabled algorithm is applied, there may be multiple lesions in a patient, and a CADe-enabled algorithm may present multiple false positives. In this case, it would be more appropriate to evaluate the algorithm's diagnostic accuracy using sensitivity and the number of false positives instead of sensitivity and specificity. If the threshold value is set too high for the algorithm's internal continuous output values, the sensitivity decreases, as does the number of false positives; if the threshold value is set too low, the sensitivity increases, but the number of false positives increases as well. The FROC curve is a graph drawn by plotting the sensitivity on the y-axis and the mean number of false positives instead of 1 - specificity on the x-axis (<xref ref-type="fig" rid="F4">Fig. 4</xref>) [<xref rid="B7" ref-type="bibr">7</xref>]. The mean number of false positives can be calculated in several ways, depending on the situation. For example, they can be calculated using the mean number per patient or per image. There are also slightly modified forms of the FROC method. For further details, see the relevant literature [<xref rid="B8" ref-type="bibr">8</xref><xref rid="B9" ref-type="bibr">9</xref>].</p></sec><sec><title>Calibration Accuracy</title><p>The performance indicators described above are all indicators of discrimination accuracy. Calibration accuracy, on the other hand, which describes how similar the predicted probability values presented by an AI algorithm (for example, &#x0201c;The probability of this lesion to be cancerous is X%&#x0201d;) are to the actual probabilities, should be evaluated separately [<xref rid="B6" ref-type="bibr">6</xref>]. According to the Bayes' theorem of probability, the actual probability is greatly influenced by the pretest probability, also referred to as disease prevalence. It follows that a probability presented by an AI algorithm that does not take into consideration the pretest probability is likely inaccurate. Therefore, a rigorous evaluation of calibration accuracy is required for all AI algorithms that present probabilities directly to users. Particular care should be taken, as calibration accuracy is often overlooked when evaluating the performance of an AI algorithm [<xref rid="B6" ref-type="bibr">6</xref>]. It goes beyond the scope of this paper to go into details about calibration accuracy. For further details, see the relevant literature.</p></sec></sec><sec><title>Limited Generalizability of AI Algorithm Performance in Healthcare</title><sec><title>Overfitting in AI Algorithms for Medical Diagnosis/Prediction</title><p>Machine learning algorithms characterized by high dimensionality and mathematical complexity, such as deep learning which represents the current AI technology, have strong data dependence. Therefore, they tend to have excellent accuracy in training data, but their performance deteriorates in external data not used for training. This phenomenon is called &#x02018;overfitting&#x02019; [<xref rid="B10" ref-type="bibr">10</xref>]. It is well known that AI algorithms for medical diagnosis/prediction are particularly prone to overfitting. There are several techniques to reduce overfitting, collectively termed regularization, but regularization alone is often insufficient to address overfitting in AI algorithms for medical diagnosis/prediction. For this reason, most current AI algorithms in medicine may fail to generalize [<xref rid="B11" ref-type="bibr">11</xref>]. <xref rid="T1" ref-type="table">Table 1</xref> shows some examples of the limited generalizability of AI algorithms for medical diagnosis/prediction [<xref rid="B12" ref-type="bibr">12</xref><xref rid="B13" ref-type="bibr">13</xref><xref rid="B14" ref-type="bibr">14</xref><xref rid="B15" ref-type="bibr">15</xref><xref rid="B16" ref-type="bibr">16</xref>]. As shown in these examples, in real-world clinical settings, the diagnostic accuracy of these AI algorithms decreases or the presented probability becomes incorrect, and the threshold value set for converting the internal output value into the final result does not fit.</p></sec><sec><title>Reasons for High Overfitting in AI Algorithms for Medical Diagnosis/Prediction</title><p>The fundamental reason behind the high overfitting and limited generalizability of AI algorithms for medical diagnosis/prediction is their failure to sufficiently reflect the real-world situations in the data sets used to train the AI algorithms [<xref rid="B11" ref-type="bibr">11</xref><xref rid="B17" ref-type="bibr">17</xref><xref rid="B18" ref-type="bibr">18</xref><xref rid="B19" ref-type="bibr">19</xref>]. Several factors are involved in this phenomenon. First, medical data are highly heterogeneous. Even if patients have the same disease, their other characteristics such as age, sex, disease severity, underlying conditions, or comorbidities often differ across the capacity, type, and location of the hospitals. The variety and distribution of similar diseases or differential diagnoses found in patients suspected of a particular disease but who do not have the disease also often differ across hospitals. Disease prevalence may also vary from one hospital to another. Simply put, the situation of one hospital often cannot be applied to another. The fact that hospitals utilize different devices also contributes to the data heterogeneity. For example, in the case of imaging devices, such as computed tomography and MRI, an AI algorithm tuned to the image properties of one vendor may not work well on the images obtained with the scanners from another manufacturer. Furthermore, advances in healthcare equipment and technologies lead to constant changes in therapeutic agents and diagnostic tools, which creates temporal heterogeneity. For example, AI algorithms trained with data including treatment agents used in the past cannot function correctly in situations where different therapeutic agents are used; likewise, AI that has been trained on images from old imaging devices may not work properly on images from new devices. To overcome this data heterogeneity, it is necessary to train AI with a huge amount data systematically collected from as many hospitals as possible, which is a labor- and time-intensive procedure requiring committed medical professionals and a large amount of material resources. The paradoxical combination of high data heterogeneity and insufficient data for training AI algorithms often results in a situation where the training data sets do not sufficiently reflect the clinical settings in which an algorithm is intended to be used. In addition, real-world medical data contain diverse gray areas and noise elements. There are cases in which no clear reference standards are available to determine the presence or absence of a certain disease. The presence vs. absence of a disease, as described in a binary variable (0 or 1), may only represent a few specific points along a continuous phase of change in the development and progress of an entire disease process. Nevertheless, data allowing a clear binary disease classification (present/absent) are often selectively used for AI training purposes [<xref rid="B20" ref-type="bibr">20</xref>]. Also, data from which noise elements are removed for more efficient processing by computer programs are used preferentially.</p></sec><sec><title>Implications of the Limited Generalizability</title><p>First, when evaluating AI algorithm performance, it is important to perform external validation using external data, as discussed further later [<xref rid="B6" ref-type="bibr">6</xref><xref rid="B10" ref-type="bibr">10</xref><xref rid="B11" ref-type="bibr">11</xref><xref rid="B21" ref-type="bibr">21</xref><xref rid="B22" ref-type="bibr">22</xref><xref rid="B23" ref-type="bibr">23</xref><xref rid="B24" ref-type="bibr">24</xref><xref rid="B25" ref-type="bibr">25</xref><xref rid="B26" ref-type="bibr">26</xref><xref rid="B27" ref-type="bibr">27</xref><xref rid="B28" ref-type="bibr">28</xref><xref rid="B29" ref-type="bibr">29</xref>]. Given that an AI algorithm's performance in a clinical envirionment may differ from when it was developed, it is best to conduct external validation directly in the target clinical environment. Nevertheless, insufficient external validation of AI algorithms frequently poses problem [<xref rid="B30" ref-type="bibr">30</xref>]. Second, instead of blindly accepting the result presented by an AI algorithm, medical professionals should make final decisions after due consideration to the clinical situation and other relevant information. The threshold value described above should also be properly tuned to the clinical situation. For these reasons, while high-performance AI might replace medical professionals for specific functions under limited conditions, AI is not an autonomous tool to replace a medical professional; its role is limited to providing competent assistance and information to the medical professional. Third, as a method to improve the generalizability of an AI algorithm, an additional training round may be administered using data from target hospitals and specific clinical settings prior to its use in the practice. There are concerns, however, that an AI algorithm's initial accuracy may be impaired if it is trained with additional data that include errors and biases. Unlike locked software algorithms, AI algorithms can change through continuous learning, and continuous evaluation and management are required, even after device approval. As the current device-approval system has no concrete provisions for continuous evaluation and management, this aspect should be addressed in the future.</p></sec></sec><sec><title>Evaluating AI Algorithm Performance: Classification according to Data Used</title><p>The methods of evaluating AI algorithms' performance can be classified according to the characteristics of the data used for the evaluation. Before explaining these classifications, it is necessary to understand the term &#x02018;validation&#x02019; clearly. In addition to its ordinary meaning (i.e., verification or confirmation), as used in this article, validation is also a technical term in the machine learning field, referring to the process of adjusting hyperparameters when making AI algorithms [<xref rid="B31" ref-type="bibr">31</xref>]. The process of adjusting hyperparameters is also called tuning to avoid confusion; however, validation is more widely used to indicate the procedure in AI-related literature [<xref rid="B31" ref-type="bibr">31</xref>]. On the other hand, validation test or test is used instead of validation to indicate verification of algorithm performance and distinguish it from the process of adjusting hyperparameters [<xref rid="B32" ref-type="bibr">32</xref><xref rid="B33" ref-type="bibr">33</xref>].</p><sec><title>Internal Validation</title><p>Internal validation tends to overestimate the performance of AI algorithms. Therefore, internal validation has a role in checking the algorithm performance while developing it rather than confirming the performance of a finished model. External validation is required to determine the performance of AI algorithms. Results from internal validation can be used to compare the results of external validation. Cross-validation and split-sample validation are categorized as types of internal validation.</p><sec><title>Cross-Validation</title><p>A well-known example of cross-validation is k-fold cross-validation [<xref rid="B32" ref-type="bibr">32</xref>]. The original data are split into k number of groups; one group is retained as the testing data, and the remaining groups form the training data. At each iteration, one group after another is used as the testing data until every group has been used once. Finally, the mean of all results is obtained. This method can be used for a preliminary evaluation of an algorithm's performance when the original data size is small. However, it is considered inadequate for algorithm performance validation.</p></sec><sec><title>Split-Sample Validation</title><p>In split-sample validation, the original data are split into three sets (training set, tuning set, and test set). The test set is not used for training and tuning of the AI algorithm; it is used to test the performance of the trained and tuned AI algorithm (<xref ref-type="fig" rid="F5">Fig. 5</xref>) [<xref rid="B32" ref-type="bibr">32</xref>]. The data can be split randomly or stratified according to the data-collection period. Split-sample validation is better suited for internal validation than cross-validation.</p></sec></sec><sec><title>External Validation</title><p>External validation refers to evaluation of an AI algorithm's performance using data collected independently instead of the original data (<xref ref-type="fig" rid="F5">Fig. 5</xref>). Typically, a data set provided by external hospitals is used instead of the one that provided the training data. As shown in <xref ref-type="fig" rid="F2">Figure 2</xref>, to evaluate the performance of an AI algorithm, two categories of data are required: one that contains the condition targeted by the AI algorithm for diagnosis or prediction and one that does not. Depending on the method of collecting these validation data, external validation studies can be largely divided into diagnostic case-control and diagnostic cohort studies [<xref rid="B34" ref-type="bibr">34</xref>].</p><sec><title>Diagnostic Case-Control Study</title><p>In diagnostic case-control studies, samples with and without the target condition to be diagnosed or predicted by an AI algorithm are collected separately. For example, when evaluating the performance of an AI algorithm that discriminates the presence or absence of lung cancer by analyzing chest X-ray images, a certain number of chest X-ray images with lung cancer (case) and without lung cancer (control) are collected. When data is collected in this way, prevalence (in the example case, the proportion of chest X-rays with lung cancer among the total number of chest X-ray images) is artificially designated, unlike the natural prevalence observed in real-world settings. Moreover, the method by which the images with and without lung cancer are collected may affect the degree of variation in the size and shape of the included lung cancers, the presence or variety of lung lesions that may mimic lung cancer in patients without lung cancer, and the presence or degree of various conditions or underlying diseases and comorbidities that can affect the discovery of lung cancer, all of which are collectively referred to as &#x02018;spectrum.&#x02019; Data collected in this case-control manner often differ from the natural spectrum in clinical settings due to selection bias [<xref rid="B35" ref-type="bibr">35</xref>]. This artificial spectrum and prevalence affect the evaluation of algorithm performance [<xref rid="B2" ref-type="bibr">2</xref><xref rid="B6" ref-type="bibr">6</xref>].</p></sec><sec><title>Diagnostic Cohort Study</title><p>In a diagnostic cohort study, the clinical setting in which an AI algorithm will be applied is predefined; data are collected based on this definition, regardless of the presence/absence of the disease to be diagnosed or predicted by the AI algorithm. In the case of an AI algorithm discriminating the presence or absence of lung cancer on chest X-rays, the eligibility criteria (for example, &#x0201c;adults 55 years of age and older with X pack-year smoking history&#x0201d;) are defined. The AI algorithm performance is assessed on X-ray images taken from patients who are continuously recruited or randomly selected from those satisfying the eligibility criteria. Some of the recruited patients may have lung cancer, and others may not. In this way, data with the natural spectrum and prevalence can be collected, and the performance and the threshold value determined in the validation study can be more directly applied to the clinical setting defined by the eligibility criteria. Whereas a diagnostic case-control study evaluates performance in a somewhat artificial experimental setting, a diagnostic cohort study evaluates performance in a more realistic clinical environment. It is essential to clearly understand the actual clinical setting for which the AI algorithm is intended when determining the concrete eligibility criteria to reflect the clinical setting adequately.</p></sec><sec><title>Differences between Diagnostic Case-Control Study and Diagnostic Cohort Study</title><p>Diagnostic case-control and diagnostic cohort studies are designed for different purposes. The former aims to evaluate the overall &#x02018;technical performance&#x02019; of an AI algorithm for the intended diagnosis/prediction. Although prospective studies offer certain advantages, retrospective studies can also be used to validate the technical performance of an AI algorithm, subject to the availability of a validation data set containing well-distributed examples of various difficulty levels matching the purpose of the AI algorithm. Diagnostic cohort studies aims to evaluate the &#x02018;clinical performance&#x02019; of an AI algorithm in specific clinical settings or patient groups. Therefore, compared to a diagnostic case-control study, a diagnostic cohort study has a clearer and more concrete notion of the clinical target population, i.e., clinical indication. For diagnostic cohort studies, a prospective study design is recommended. In general, the technical performance of an AI algorithm is first tested via a diagnostic case-control study, then the clinical performance is tested via a diagnostic cohort study. There is a tendency for performance to be rated higher in diagnostic case-control studies than in diagnostic cohort studies.</p></sec><sec><title>Validation Using Standard Data Sets</title><p>Some are of the opinion that standard data sets should be used for performance validation of AI algorithms. The process of collecting standard data is often similar to that of collecting data for diagnostic case-control studies. Therefore, well-established standard data sets may prove suitable for evaluating the technical performance of AI algorithms. Such standard sets would be rendered more efficient when collected from many different hospitals. One of the major drawbacks of standard data is that AI algorithms that perform well only on standard data can emerge. A standard data set can be compared to the College Entrance Exam (Korean equivalent of SAT). Every year, new questions are formulated under thorough security measures, because reusing questions does not allow for the proper evaluation of a student's performance. Likewise, a standard data set that is not continuously updated may be subject to the &#x0201c;leaking test questions&#x0201d; effect. Moreover, to successfully generate a genuinely representative standard data set, meticulous prior research is needed on fundamental issues such as the conditions required for a standard data set to test the performance of AI algorithms sufficiently and objectively.</p></sec></sec></sec><sec><title>Passing Criteria for AI Algorithm Performance Evaluation</title><p>When evaluating AI algorithm performance, a criterion for determining whether the performance is adequate should also be prepared. This can be done by comparing the stand-alone performance of an AI algorithm with an absolute criterion (e.g., 90% or higher accuracy), which may involve ambiguity. It may be more intuitive to prepare a control method against which you can check the performance of an AI algorithm. These may include comparing AI with existing similar AI algorithms, other tests, or medical professionals as the control, as well as comparing medical professionals using AI with those not using AI as the control. While the focus of former is on the performance of AI algorithms themselves, the latter reflects the role of AI as an auxiliary tool providing information to medical professionals. The medical professionals may include both experienced and unexperienced doctors, and more useful information will likely be derived when the comparative results are analyzed according to their level of experience. In a relative comparison with a control, it is necessary to set the performance-difference criteria (e.g., less than 5%) at which the two compared results are considered statistically equivalent or significantly different. The passing criterion for absolute performance evaluation or for the relative comparison with a control cannot be set uniformly; it must be set according to the function of each AI algorithm and each clinical setting. Once the criterion is established, the sample size needed for performance evaluation can be calculated using well-known statistical methods [<xref rid="B36" ref-type="bibr">36</xref><xref rid="B37" ref-type="bibr">37</xref><xref rid="B38" ref-type="bibr">38</xref><xref rid="B39" ref-type="bibr">39</xref>].</p></sec><sec><title>Evaluation of the Clinical Utility of AI Algorithms</title><p>High accuracy does not necessarily mean an AI algorithm can improve clinical outcomes. AI algorithms are computerized aids that provide information to medical professionals to assist them in the clinical decision process. For any computerized tool to be useful, how the tool is integrated into the workflow is critical besides its performance. An AI algorithm must deliver information to the right person in the right way. Likewise, the coordinating doctor's response to the information from AI and the actions taken greatly affect the outcomes of patient care. Since the final clinical outcomes are achieved through the therapeutic or prophylactic actions taken based on diagnostic decisions, if no therapeutic or prophylactic actions are taken, no effects are made to the clinical outcomes. On the other hand, therapeutic or prophylactic actions can also bring about adverse reactions in some patients. Therefore, it is crucial to directly assess the effect of AI on clinical outcomes apart from its performance [<xref rid="B40" ref-type="bibr">40</xref>]. Such an evaluation is called validation of &#x02018;clinical utility.&#x02019; Utility and efficacy are not interchangeable terms. Technical performance, clinical performance, and clinical utility are all indicators of efficacy of different levels and characters.</p><p>An example of validating clinical utility is provided in a study on an AI algorithm developed in the United Kingdom that monitors and analyzes the uterine contractions of a woman in labor and the heartbeat of the fetus and sends a real-time alert to the doctor when a fetal problem is suspected [<xref rid="B41" ref-type="bibr">41</xref>]. After verifying the accuracy of the algorithm, the investigators randomly assigned high-risk women in labor into AI-aided and AI-unaided groups to compare the outcomes of care [<xref rid="B41" ref-type="bibr">41</xref>]. Although the AI algorithm showed high accuracy in recognizing abnormal heartbeats, no significant difference in clinical outcome was observed between the experimental and control groups for both fetuses and mothers. As a result, the study could not demonstrate the clinical utility of the AI algorithm in terms of medical benefits to patients.</p><p>As shown in this example, validating the clinical utility of AI algorithms involves determining any differences in patient outcomes between AI-aided and AI-unaided patient care. Ideally, a randomized clinical trial should be conducted to prevent the effect of confounding variables in the intergroup comparison. However, since randomized clinical trials are not always possible, the results of prospective or retrospective observational research adjusted for confounding variables may be used. There are also AI algorithms that may be clinically validated sufficiently via performance validation alone without clinical utility validation. The appropriate level of clinical validation tailored to individual AI algorithms and clinical settings should be determined by medical experts. <xref rid="T2" ref-type="table">Table 2</xref> provides a few examples of randomized controlled trials examining AI algorithms [<xref rid="B41" ref-type="bibr">41</xref><xref rid="B42" ref-type="bibr">42</xref><xref rid="B43" ref-type="bibr">43</xref><xref rid="B44" ref-type="bibr">44</xref><xref rid="B45" ref-type="bibr">45</xref><xref rid="B46" ref-type="bibr">46</xref>].</p></sec><sec><title>Clinical Validation of AI Algorithms from the Viewpoint of Device Approval and Insurance Coverage</title><p>Device approval, issued by entities such as the Korean Ministry of Food and Drug Safety (MFDS), the US Food and Drug Administration, and the European Commission (CE Marking), and decisions surrounding insurance coverage involve not only scientific principles but also sociopolitical factors. Therefore, AI device approval and insurance coverage may vary according to country, period, and social factors, and they cannot be explained from one perspective. This paper provides scientific principles alone related to AI device approval and insurance coverage. For the definitions of technical performance, clinical performance, clinical utility, diagnostic case-control study, and diagnostic cohort study, see explanations in the corresponding parts of this article.</p><sec><title>Differences between Pharmaceuticals and Diagnostic Devices</title><p>Most medical AI algorithms are diagnostic devices and thus subject to the process of diagnostic device approval and insurance coverage. For a proper understanding of AI algorithms in this context, it is useful to clarify the difference between diagnostic devices and pharmaceutical agents.</p><p>For the approval of a pharmaceutical agent, it is generally necessary to prove, in a phase III clinical trial, that a given pharmaceutical agent improves patient treatment outcomes when used within a specific patient population. In other words, the clinical utility should be demonstrated for a particular indication. In contrast, approval of diagnostic devices does not require high-level clinical evidence applied to pharmaceutical agents, and generally focuses on technical performance validation. Of course, higher-level clinical validation data, if available, may enable a more thorough evaluation.</p><p>Insurance coverage is an act that an insurer pays for medical services (i.e., the use of pharmaceutical agents or medical devices) delivered to policyholders (i.e., patients) who pay premiums. Therefore, it is important to demonstrate the clinical utility (i.e., patient benefit) of the medical services provided. Given that a medical service can be useful to one patient and useless to another, its indications must be specified when applying insurance coverage. Coverage of a medical service provided to patients (i.e., payment for medical fees indirectly by patients through insurance premium) in whom clinical utility has not been proven is unusual and unreasonable. In the case of therapeutic agents, the conditions for insurance coverage are essentially the same as those for their approval. Therefore, after approval, reasonably priced drugs are generally automatically covered by insurance. For diagnostic devices, however, approval is usually issued after technical performance validation, falling short of the requirements for clinical utility validation needed for insurance coverage. For this reason, device approval is not automatically associated with insurance coverage. A diagnostic device approved by regulatory agencies can be marketed and used for clinical practice. Later, if further clinical testing reveals clinical conditions in which the device is beneficial for patients, insurance coverage may include these indications. For example, even if MRI and ultrasonography have been approved by their proven technical performances, they are not covered by insurance until their use has proven beneficial for patient care in more specified clinical conditions and patient populations.</p></sec><sec><title>Device Approval for AI Algorithms</title><p>For device approval of an AI algorithm, its technical performance validation must be sufficiently documented at least. An AI algorithm's technical performance validation can be performed through external validation such as diagnostic case-control study. A prospective study is advantageous, if possible, but a retrospective study can also provide technical performance validation of an AI algorithm, subject to the availability of a validation data set containing well-distributed examples of various difficulty levels matching its purpose. The conditions under which the AI algorithm operates well should be clarified and documented during the technical performance validation (e.g., devices and image acquisition methods, etc. that work well with the AI). It should be noted that AI device approval is merely permission to use the device on patients and to bring it to the market for that purpose. In other words, although a certain level of safety and efficacy of the AI should be demonstrated (typically through technical performance validation), AI device approval does not indicate whether the AI device is beneficial or valuable for patient care [<xref rid="B25" ref-type="bibr">25</xref><xref rid="B26" ref-type="bibr">26</xref><xref rid="B47" ref-type="bibr">47</xref>]. Medical professionals involved in patient care should conduct further clinical validation and evaluation of the approved AI device to verify its clinical utility and ensure its safe and efficacious clinical application [<xref rid="B47" ref-type="bibr">47</xref><xref rid="B48" ref-type="bibr">48</xref>]. Moreover, as it is difficult to investigate all matters related to generalizability of the AI algorithm during the device-approval process, it is important to further clarify the circumstances under which the AI output is accurate/inaccurate.</p><p>These scientific principles are adopted in the Guidelines for Big Data- and AI-based Medical Device Approval revised and released by the MFDS for the general public. These guidelines state that the sample data used in clinical investigations for an AI-based device seeking device approval should comprise independent data sets other than those used during the product development process. In other words, external validation is required. Use of reliable retrospective data sets are allowed for the validation for device approval by MFDS, if appropriate. Applicants may decide whether a prospective or retrospective clinical study design is suitable for the product.</p></sec><sec><title>Insurance Coverage for AI-Based Medical Device</title><p>Regarding insurance coverage for AI-based devices, the Health Insurance Review and Assessment Service under the Korean Ministry of Health and Welfare released the Guidelines for the Evaluation for Medical Insurance Coverage for Innovative Medical Technology in December 2019. These guidelines added some flexibility to the scientific principles of medical insurance coverage. They state that, when improved patient outcomes or significant improvement in diagnostic accuracy with the use of an AI-based device compared to conventional care is verified, extra compensation through insurance coverage may be considered (the demonstration of cost-effectiveness is also included in the guidelines; we omit it because it is beyond the scope of this paper). While results from a prospective or retrospective research on patient outcomes adjusting for confounding variables or a randomized clinical trial is recommended for the evaluation, a diagnostic cohort study may also be accepted on a case-by-case basis for external validation of the clinical performance of AI. That is, for insurance coverage, clinical utility should be demonstrated in the form of improved patient outcomes; however, under certain circumstances, demonstration in a diagnostic cohort study of a significant improvement in diagnostic accuracy with the use of an AI-based device for a specific clinical condition/patient population may also satisfy the conditions for insurance coverage.</p></sec></sec><sec><title>CONCLUSIONS</title><p>We examined the key principles of clinical validation, device approval, and insurance coverage of AI algorithms for medical diagnosis/prediction. When evaluating the discrimination performance of AI, the Dice similarity coefficient, sensitivity, specificity, ROC curve, and FROC curve are widely used. In the case of an AI algorithm presenting probability directly, calibration performance should be evaluated as well. Most currently available AI algorithms for medical diagnosis and prediction have limited generalizability to real-world healthcare settings of their performance shown in their development stage or through internal validation. This highlights the importance of external validation of performance in the clinical validation of AI algorithms. It should also be considered that AI is generally not meant to serve as a stand-alone tool. It is an auxiliary tool providing information to the medical professional. For external validation of AI performance, diagnostic case-control and diagnostic cohort studies may be conducted. The former evaluates the technical performance of an AI algorithm, while the latter evaluates the clinical performance in samples representing the target patients in real-world clinical scenarios. The ultimate clinical validation of an AI algorithm lies in the evaluation of its effect on patient outcomes. A randomized clinical trial is ideal for this validation of clinical utility. AI-device approval generally focuses on technical performance validation. Therefore, it is not used to determine whether the AI is beneficial for patient care and improves patient outcomes. Also, it is difficult to investigate all matters related to generalizability of the AI algorithm during the device-approval process. After achieving device approval, it is up to medical professionals to determine whether the approved AI algorithms are beneficial for real-world patient care. To obtain insurance coverage, it is essential to demonstrate clinical utility in the form of improved patient outcomes. As the use of AI algorithms for medical diagnosis/prediction is likely to increase in the future, the topics discussed herein should be introduced into medical-school curriculums [<xref rid="B49" ref-type="bibr">49</xref>].</p></sec></body><back><ack><title>Acknowledgments</title><p>This article is a republication of the original paper published in Korean in the Journal of the Korean Medical Association (J Korean Med Assoc 2020;63:696-708), translated into English with the original publisher's consent.</p></ack><fn-group><fn fn-type="supported-by"><p>This research was supported by a grant of the Korea Health Technology R&#x00026;D Project through the Korea Health Industry Development Institute (KHIDI), funded by the Ministry of Health &#x00026; Welfare, Republic of Korea (grant number: HI17C2410).</p></fn><fn fn-type="COI-statement"><p><bold>Conflicts of Interest:</bold> The authors have no potential conflicts of interest to disclose.</p></fn><fn fn-type="con"><p><bold>Author Contributions:</bold>
<list list-type="simple"><list-item><p><bold>Conceptualization:</bold> Seong Ho Park.</p></list-item><list-item><p><bold>Funding acquisition:</bold> Jaesoon Choi.</p></list-item><list-item><p><bold>Writing&#x02014;original draft:</bold> Seong Ho Park.</p></list-item><list-item><p><bold>Writing&#x02014;review &#x00026; editing:</bold> Jaesoon Choi, Jeong-Sik Byeon.</p></list-item></list>
</p></fn></fn-group><ref-list><ref id="B1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Topol</surname><given-names>EJ</given-names></name></person-group><article-title>High-performance medicine: the convergence of human and artificial intelligence</article-title><source>Nat Med</source><year>2019</year><volume>25</volume><fpage>44</fpage><lpage>56</lpage><pub-id pub-id-type="pmid">30617339</pub-id></element-citation></ref><ref id="B2"><label>2</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Park</surname><given-names>SH</given-names></name><name><surname>Lim</surname><given-names>TH</given-names></name></person-group><source>Artificial intelligence: guide for healthcare personnel</source><publisher-loc>Seoul</publisher-loc><publisher-name>Koonja</publisher-name><year>2020</year></element-citation></ref><ref id="B3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Do</surname><given-names>S</given-names></name><name><surname>Song</surname><given-names>KD</given-names></name><name><surname>Chung</surname><given-names>JW</given-names></name></person-group><article-title>Basics of deep learning: a radiologist's guide to understanding published radiology articles on deep learning</article-title><source>Korean J Radiol</source><year>2020</year><volume>21</volume><fpage>33</fpage><lpage>41</lpage><pub-id pub-id-type="pmid">31920027</pub-id></element-citation></ref><ref id="B4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Choi</surname><given-names>JS</given-names></name><name><surname>Han</surname><given-names>BK</given-names></name><name><surname>Ko</surname><given-names>ES</given-names></name><name><surname>Bae</surname><given-names>JM</given-names></name><name><surname>Ko</surname><given-names>EY</given-names></name><name><surname>Song</surname><given-names>SH</given-names></name><etal/></person-group><article-title>Effect of a deep learning framework-based computer-aided diagnosis system on the diagnostic performance of radiologists in differentiating between malignant and benign masses on breast ultrasonography</article-title><source>Korean J Radiol</source><year>2019</year><volume>20</volume><fpage>749</fpage><lpage>758</lpage><pub-id pub-id-type="pmid">30993926</pub-id></element-citation></ref><ref id="B5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Park</surname><given-names>SH</given-names></name><name><surname>Goo</surname><given-names>JM</given-names></name><name><surname>Jo</surname><given-names>CH</given-names></name></person-group><article-title>Receiver operating characteristic (ROC) curve: practical review for radiologists</article-title><source>Korean J Radiol</source><year>2004</year><volume>5</volume><fpage>11</fpage><lpage>18</lpage><pub-id pub-id-type="pmid">15064554</pub-id></element-citation></ref><ref id="B6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Park</surname><given-names>SH</given-names></name><name><surname>Han</surname><given-names>K</given-names></name></person-group><article-title>Methodologic guide for evaluating clinical performance and effect of artificial intelligence technology for medical diagnosis and prediction</article-title><source>Radiology</source><year>2018</year><volume>286</volume><fpage>800</fpage><lpage>809</lpage><pub-id pub-id-type="pmid">29309734</pub-id></element-citation></ref><ref id="B7"><label>7</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Tajbakhsh</surname><given-names>N</given-names></name><name><surname>Gurudu</surname><given-names>SR</given-names></name><name><surname>Liang</surname><given-names>J</given-names></name></person-group><source>Automatic polyp detection in colonoscopy videos using an ensemble of convolutional neural networks</source><conf-name>Proceedings of 2015 IEEE 12th International Symposium on Biomedical Imaging</conf-name><conf-date>2015 Apr 16-19</conf-date><conf-loc>New York, USA</conf-loc><publisher-name>IEEE</publisher-name><year>2015</year><fpage>79</fpage><lpage>83</lpage></element-citation></ref><ref id="B8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moskowitz</surname><given-names>CS</given-names></name></person-group><article-title>Using free-response receiver operating characteristic curves to assess the accuracy of machine diagnosis of cancer</article-title><source>JAMA</source><year>2017</year><volume>318</volume><fpage>2250</fpage><lpage>2251</lpage><pub-id pub-id-type="pmid">29234793</pub-id></element-citation></ref><ref id="B9"><label>9</label><element-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Chakraborty</surname><given-names>DP</given-names></name></person-group><source>Welcome to Prof. Dev Chakraborty's FROC methodology. Devchakraborty.com Web site</source><year>Published 2019</year><date-in-citation content-type="access-date">Accessed September 14, 2020</date-in-citation><comment><ext-link ext-link-type="uri" xlink:href="http://www.devchakraborty.com/">http://www.devchakraborty.com/</ext-link></comment></element-citation></ref><ref id="B10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mutasa</surname><given-names>S</given-names></name><name><surname>Sun</surname><given-names>S</given-names></name><name><surname>Ha</surname><given-names>R</given-names></name></person-group><article-title>Understanding artificial intelligence based radiology studies: what is overfitting?</article-title><source>Clin Imaging</source><year>2020</year><volume>65</volume><fpage>96</fpage><lpage>99</lpage><pub-id pub-id-type="pmid">32387803</pub-id></element-citation></ref><ref id="B11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kelly</surname><given-names>CJ</given-names></name><name><surname>Karthikesalingam</surname><given-names>A</given-names></name><name><surname>Suleyman</surname><given-names>M</given-names></name><name><surname>Corrado</surname><given-names>G</given-names></name><name><surname>King</surname><given-names>D</given-names></name></person-group><article-title>Key challenges for delivering clinical impact with artificial intelligence</article-title><source>BMC Med</source><year>2019</year><volume>17</volume><elocation-id>195</elocation-id><pub-id pub-id-type="pmid">31665002</pub-id></element-citation></ref><ref id="B12"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zech</surname><given-names>JR</given-names></name><name><surname>Badgeley</surname><given-names>MA</given-names></name><name><surname>Liu</surname><given-names>M</given-names></name><name><surname>Costa</surname><given-names>AB</given-names></name><name><surname>Titano</surname><given-names>JJ</given-names></name><name><surname>Oermann</surname><given-names>EK</given-names></name></person-group><article-title>Variable generalization performance of a deep learning model to detect pneumonia in chest radiographs: a cross-sectional study</article-title><source>PLoS Med</source><year>2018</year><volume>15</volume><elocation-id>e1002683</elocation-id><pub-id pub-id-type="pmid">30399157</pub-id></element-citation></ref><ref id="B13"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ting</surname><given-names>DSW</given-names></name><name><surname>Cheung</surname><given-names>CY</given-names></name><name><surname>Lim</surname><given-names>G</given-names></name><name><surname>Tan</surname><given-names>GSW</given-names></name><name><surname>Quang</surname><given-names>ND</given-names></name><name><surname>Gan</surname><given-names>A</given-names></name><etal/></person-group><article-title>Development and validation of a deep learning system for diabetic retinopathy and related eye diseases using retinal images from multiethnic populations with diabetes</article-title><source>JAMA</source><year>2017</year><volume>318</volume><fpage>2211</fpage><lpage>2223</lpage><pub-id pub-id-type="pmid">29234807</pub-id></element-citation></ref><ref id="B14"><label>14</label><element-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Ridley</surname><given-names>EL</given-names></name></person-group><source>Deep-learning algorithms need real-world testing. Auntminnie.com Web site</source><year>Published 2018</year><date-in-citation content-type="access-date">Accessed September 14, 2020</date-in-citation><comment><ext-link ext-link-type="uri" xlink:href="https://www.auntminnie.com/index.aspx?sec=nws&#x00026;sub=rad&#x00026;pag=dis&#x00026;ItemID=123871">https://www.auntminnie.com/index.aspx?sec=nws&#x00026;sub=rad&#x00026;pag=dis&#x00026;ItemID=123871</ext-link></comment></element-citation></ref><ref id="B15"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hwang</surname><given-names>EJ</given-names></name><name><surname>Park</surname><given-names>S</given-names></name><name><surname>Jin</surname><given-names>KN</given-names></name><name><surname>Kim</surname><given-names>JI</given-names></name><name><surname>Choi</surname><given-names>SY</given-names></name><name><surname>Lee</surname><given-names>JH</given-names></name><etal/></person-group><article-title>Development and validation of a deep learning&#x02013;based automated detection algorithm for major thoracic diseases on chest radiographs</article-title><source>JAMA Netw Open</source><year>2019</year><volume>2</volume><elocation-id>e191095</elocation-id><pub-id pub-id-type="pmid">30901052</pub-id></element-citation></ref><ref id="B16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>JH</given-names></name><name><surname>Joo</surname><given-names>I</given-names></name><name><surname>Kang</surname><given-names>TW</given-names></name><name><surname>Paik</surname><given-names>YH</given-names></name><name><surname>Sinn</surname><given-names>DH</given-names></name><name><surname>Ha</surname><given-names>SY</given-names></name><etal/></person-group><article-title>Deep learning with ultrasonography: automated classification of liver fibrosis using a deep convolutional neural network</article-title><source>Eur Radiol</source><year>2020</year><volume>30</volume><fpage>1264</fpage><lpage>1273</lpage><pub-id pub-id-type="pmid">31478087</pub-id></element-citation></ref><ref id="B17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ghassemi</surname><given-names>M</given-names></name><name><surname>Naumann</surname><given-names>T</given-names></name><name><surname>Schulam</surname><given-names>P</given-names></name><name><surname>Beam</surname><given-names>AL</given-names></name><name><surname>Chen</surname><given-names>IY</given-names></name><name><surname>Ranganath</surname><given-names>R</given-names></name></person-group><article-title>Practical guidance on artificial intelligence for health-care data</article-title><source>Lancet Digit Health</source><year>2019</year><volume>1</volume><fpage>e157</fpage><lpage>e159</lpage><pub-id pub-id-type="pmid">33323184</pub-id></element-citation></ref><ref id="B18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Park</surname><given-names>SH</given-names></name><name><surname>Kim</surname><given-names>YH</given-names></name><name><surname>Lee</surname><given-names>JY</given-names></name><name><surname>Yoo</surname><given-names>S</given-names></name><name><surname>Kim</surname><given-names>CJ</given-names></name></person-group><article-title>Ethical challenges regarding artificial intelligence in medicine from the perspective of scientific editing and peer review</article-title><source>Sci Ed</source><year>2019</year><volume>6</volume><fpage>91</fpage><lpage>98</lpage></element-citation></ref><ref id="B19"><label>19</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Willemink</surname><given-names>MJ</given-names></name><name><surname>Koszek</surname><given-names>WA</given-names></name><name><surname>Hardell</surname><given-names>C</given-names></name><name><surname>Wu</surname><given-names>J</given-names></name><name><surname>Fleischmann</surname><given-names>D</given-names></name><name><surname>Harvey</surname><given-names>H</given-names></name><etal/></person-group><article-title>Preparing medical imaging data for machine learning</article-title><source>Radiology</source><year>2020</year><volume>295</volume><fpage>4</fpage><lpage>15</lpage><pub-id pub-id-type="pmid">32068507</pub-id></element-citation></ref><ref id="B20"><label>20</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Adamson</surname><given-names>AS</given-names></name><name><surname>Welch</surname><given-names>HG</given-names></name></person-group><article-title>Machine learning and the cancer-diagnosis problem-no gold standard</article-title><source>N Engl J Med</source><year>2019</year><volume>381</volume><fpage>2285</fpage><lpage>2287</lpage><pub-id pub-id-type="pmid">31826337</pub-id></element-citation></ref><ref id="B21"><label>21</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bluemke</surname><given-names>DA</given-names></name><name><surname>Moy</surname><given-names>L</given-names></name><name><surname>Bredella</surname><given-names>MA</given-names></name><name><surname>Ertl-Wagner</surname><given-names>BB</given-names></name><name><surname>Fowler</surname><given-names>KJ</given-names></name><name><surname>Goh</surname><given-names>VJ</given-names></name><etal/></person-group><article-title>Assessing radiology research on artificial intelligence: a brief guide for authors, reviewers, and readers&#x02014;from the radiology editorial board</article-title><source>Radiology</source><year>2020</year><volume>294</volume><fpage>487</fpage><lpage>489</lpage><pub-id pub-id-type="pmid">31891322</pub-id></element-citation></ref><ref id="B22"><label>22</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mehta</surname><given-names>MC</given-names></name><name><surname>Katz</surname><given-names>IT</given-names></name><name><surname>Jha</surname><given-names>AK</given-names></name></person-group><article-title>Transforming global health with AI</article-title><source>N Engl J Med</source><year>2020</year><volume>382</volume><fpage>791</fpage><lpage>793</lpage><pub-id pub-id-type="pmid">32101661</pub-id></element-citation></ref><ref id="B23"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nevin</surname><given-names>L</given-names></name></person-group><collab>PLOS medicine editors</collab><article-title>Advancing the beneficial use of machine learning in health care and medicine: toward a community understanding</article-title><source>PLoS Med</source><year>2018</year><volume>15</volume><elocation-id>e1002708</elocation-id><pub-id pub-id-type="pmid">30500811</pub-id></element-citation></ref><ref id="B24"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nsoesie</surname><given-names>EO</given-names></name></person-group><article-title>Evaluating artificial intelligence applications in clinical settings</article-title><source>JAMA Netw Open</source><year>2018</year><volume>1</volume><elocation-id>e182658</elocation-id><pub-id pub-id-type="pmid">30646173</pub-id></element-citation></ref><ref id="B25"><label>25</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parikh</surname><given-names>RB</given-names></name><name><surname>Obermeyer</surname><given-names>Z</given-names></name><name><surname>Navathe</surname><given-names>AS</given-names></name></person-group><article-title>Regulation of predictive analytics in medicine</article-title><source>Science</source><year>2019</year><volume>363</volume><fpage>810</fpage><lpage>812</lpage><pub-id pub-id-type="pmid">30792287</pub-id></element-citation></ref><ref id="B26"><label>26</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Park</surname><given-names>SH</given-names></name><name><surname>Do</surname><given-names>KH</given-names></name><name><surname>Choi</surname><given-names>JI</given-names></name><name><surname>Sim</surname><given-names>JS</given-names></name><name><surname>Yang</surname><given-names>DM</given-names></name><name><surname>Eo</surname><given-names>H</given-names></name><etal/></person-group><article-title>Principles for evaluating the clinical implementation of novel digital healthcare devices</article-title><source>J Korean Med Assoc</source><year>2018</year><volume>61</volume><fpage>765</fpage><lpage>775</lpage></element-citation></ref><ref id="B27"><label>27</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Calster</surname><given-names>B</given-names></name><name><surname>Wynants</surname><given-names>L</given-names></name><name><surname>Timmerman</surname><given-names>D</given-names></name><name><surname>Steyerberg</surname><given-names>EW</given-names></name><name><surname>Collins</surname><given-names>GS</given-names></name></person-group><article-title>Predictive analytics in health care: how can we know it works?</article-title><source>J Am Med Inform Assoc</source><year>2019</year><volume>26</volume><fpage>1651</fpage><lpage>1654</lpage><pub-id pub-id-type="pmid">31373357</pub-id></element-citation></ref><ref id="B28"><label>28</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>KH</given-names></name><name><surname>Kohane</surname><given-names>IS</given-names></name></person-group><article-title>Framing the challenges of artificial intelligence in medicine</article-title><source>BMJ Qual Saf</source><year>2019</year><volume>28</volume><fpage>238</fpage><lpage>241</lpage></element-citation></ref><ref id="B29"><label>29</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tang</surname><given-names>A</given-names></name><name><surname>Tam</surname><given-names>R</given-names></name><name><surname>Cadrin-Ch&#x000ea;nevert</surname><given-names>A</given-names></name><name><surname>Guest</surname><given-names>W</given-names></name><name><surname>Chong</surname><given-names>J</given-names></name><name><surname>Barfett</surname><given-names>J</given-names></name><etal/></person-group><article-title>Canadian Association of Radiologists white paper on artificial intelligence in radiology</article-title><source>Can Assoc Radiol J</source><year>2018</year><volume>69</volume><fpage>120</fpage><lpage>135</lpage><pub-id pub-id-type="pmid">29655580</pub-id></element-citation></ref><ref id="B30"><label>30</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>DW</given-names></name><name><surname>Jang</surname><given-names>HY</given-names></name><name><surname>Kim</surname><given-names>KW</given-names></name><name><surname>Shin</surname><given-names>Y</given-names></name><name><surname>Park</surname><given-names>SH</given-names></name></person-group><article-title>Design characteristics of studies reporting the performance of artificial intelligence algorithms for diagnostic analysis of medical images: results from recently published papers</article-title><source>Korean J Radiol</source><year>2019</year><volume>20</volume><fpage>405</fpage><lpage>410</lpage><pub-id pub-id-type="pmid">30799571</pub-id></element-citation></ref><ref id="B31"><label>31</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>DW</given-names></name><name><surname>Jang</surname><given-names>HY</given-names></name><name><surname>Ko</surname><given-names>Y</given-names></name><name><surname>Son</surname><given-names>JH</given-names></name><name><surname>Kim</surname><given-names>PH</given-names></name><name><surname>Kim</surname><given-names>SO</given-names></name><etal/></person-group><article-title>Inconsistency in the use of the term &#x0201c;validation&#x0201d; in studies reporting the performance of deep learning algorithms in providing diagnosis from medical imaging</article-title><source>PLoS One</source><year>2020</year><volume>15</volume><elocation-id>e0238908</elocation-id><pub-id pub-id-type="pmid">32915901</pub-id></element-citation></ref><ref id="B32"><label>32</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Faes</surname><given-names>L</given-names></name><name><surname>Liu</surname><given-names>X</given-names></name><name><surname>Wagner</surname><given-names>SK</given-names></name><name><surname>Fu</surname><given-names>DJ</given-names></name><name><surname>Balaskas</surname><given-names>K</given-names></name><name><surname>Sim</surname><given-names>DA</given-names></name><etal/></person-group><article-title>A clinician's guide to artificial intelligence: how to critically appraise machine learning studies</article-title><source>Transl Vis Sci Technol</source><year>2020</year><volume>9</volume><elocation-id>7</elocation-id></element-citation></ref><ref id="B33"><label>33</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>X</given-names></name><name><surname>Faes</surname><given-names>L</given-names></name><name><surname>Kale</surname><given-names>AU</given-names></name><name><surname>Wagner</surname><given-names>SK</given-names></name><name><surname>Fu</surname><given-names>DJ</given-names></name><name><surname>Bruynseels</surname><given-names>A</given-names></name><etal/></person-group><article-title>A comparison of deep learning performance against health-care professionals in detecting diseases from medical imaging: a systematic review and meta-analysis</article-title><source>Lancet Digit Health</source><year>2019</year><volume>1</volume><fpage>e271</fpage><lpage>e297</lpage><pub-id pub-id-type="pmid">33323251</pub-id></element-citation></ref><ref id="B34"><label>34</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Park</surname><given-names>SH</given-names></name></person-group><article-title>Diagnostic case-control versus diagnostic cohort studies for clinical validation of artificial intelligence algorithm performance</article-title><source>Radiology</source><year>2019</year><volume>290</volume><fpage>272</fpage><lpage>273</lpage><pub-id pub-id-type="pmid">30511912</pub-id></element-citation></ref><ref id="B35"><label>35</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rutjes</surname><given-names>AW</given-names></name><name><surname>Reitsma</surname><given-names>JB</given-names></name><name><surname>Vandenbroucke</surname><given-names>JP</given-names></name><name><surname>Glas</surname><given-names>AS</given-names></name><name><surname>Bossuyt</surname><given-names>PM</given-names></name></person-group><article-title>Case-control and two-gate designs in diagnostic accuracy studies</article-title><source>Clin Chem</source><year>2005</year><volume>51</volume><fpage>1335</fpage><lpage>1341</lpage><pub-id pub-id-type="pmid">15961549</pub-id></element-citation></ref><ref id="B36"><label>36</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McGlothlin</surname><given-names>AE</given-names></name><name><surname>Lewis</surname><given-names>RJ</given-names></name></person-group><article-title>Minimal clinically important difference: defining what really matters to patients</article-title><source>JAMA</source><year>2014</year><volume>312</volume><fpage>1342</fpage><lpage>1343</lpage><pub-id pub-id-type="pmid">25268441</pub-id></element-citation></ref><ref id="B37"><label>37</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eng</surname><given-names>J</given-names></name></person-group><article-title>Sample size estimation: how many individuals should be studied?</article-title><source>Radiology</source><year>2003</year><volume>227</volume><fpage>309</fpage><lpage>313</lpage><pub-id pub-id-type="pmid">12732691</pub-id></element-citation></ref><ref id="B38"><label>38</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Obuchowski</surname><given-names>NA</given-names></name></person-group><article-title>Sample size calculations in studies of test accuracy</article-title><source>Stat Methods Med Res</source><year>1998</year><volume>7</volume><fpage>371</fpage><lpage>392</lpage><pub-id pub-id-type="pmid">9871953</pub-id></element-citation></ref><ref id="B39"><label>39</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahn</surname><given-names>S</given-names></name><name><surname>Park</surname><given-names>SH</given-names></name><name><surname>Lee</surname><given-names>KH</given-names></name></person-group><article-title>How to demonstrate similarity by using noninferiority and equivalence statistical testing in radiology research</article-title><source>Radiology</source><year>2013</year><volume>267</volume><fpage>328</fpage><lpage>338</lpage><pub-id pub-id-type="pmid">23610094</pub-id></element-citation></ref><ref id="B40"><label>40</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>X</given-names></name><name><surname>Cruz Rivera</surname><given-names>S</given-names></name><name><surname>Moher</surname><given-names>D</given-names></name><name><surname>Calvert</surname><given-names>MJ</given-names></name><name><surname>Denniston</surname><given-names>AK</given-names></name></person-group><collab>SPIRIT-AI and CONSORT-AI Working Group</collab><article-title>Reporting guidelines for clinical trial reports for interventions involving artificial intelligence: the CONSORT-AI extension</article-title><source>Nat Med</source><year>2020</year><volume>26</volume><fpage>1364</fpage><lpage>1374</lpage><pub-id pub-id-type="pmid">32908283</pub-id></element-citation></ref><ref id="B41"><label>41</label><element-citation publication-type="journal"><collab>INFANT Collaborative Group</collab><article-title>Computerised interpretation of fetal heart rate during labour (INFANT): a randomised controlled trial</article-title><source>Lancet</source><year>2017</year><volume>389</volume><fpage>1719</fpage><lpage>1729</lpage><pub-id pub-id-type="pmid">28341515</pub-id></element-citation></ref><ref id="B42"><label>42</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wijnberge</surname><given-names>M</given-names></name><name><surname>Geerts</surname><given-names>BF</given-names></name><name><surname>Hol</surname><given-names>L</given-names></name><name><surname>Lemmers</surname><given-names>N</given-names></name><name><surname>Mulder</surname><given-names>MP</given-names></name><name><surname>Berge</surname><given-names>P</given-names></name><etal/></person-group><article-title>Effect of a machine learning&#x02013;derived early warning system for intraoperative hypotension vs standard care on depth and duration of intraoperative hypotension during elective noncardiac surgery: the HYPE randomized clinical trial</article-title><source>JAMA</source><year>2020</year><volume>323</volume><fpage>1052</fpage><lpage>1060</lpage><pub-id pub-id-type="pmid">32065827</pub-id></element-citation></ref><ref id="B43"><label>43</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Repici</surname><given-names>A</given-names></name><name><surname>Badalamenti</surname><given-names>M</given-names></name><name><surname>Maselli</surname><given-names>R</given-names></name><name><surname>Correale</surname><given-names>L</given-names></name><name><surname>Radaelli</surname><given-names>F</given-names></name><name><surname>Rondonotti</surname><given-names>E</given-names></name><etal/></person-group><article-title>Efficacy of real-time computer-aided detection of colorectal neoplasia in a randomized trial</article-title><source>Gastroenterology</source><year>2020</year><volume>159</volume><fpage>512</fpage><lpage>520</lpage><pub-id pub-id-type="pmid">32371116</pub-id></element-citation></ref><ref id="B44"><label>44</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>P</given-names></name><name><surname>Liu</surname><given-names>X</given-names></name><name><surname>Berzin</surname><given-names>TM</given-names></name><name><surname>Glissen Brown</surname><given-names>JR</given-names></name><name><surname>Liu</surname><given-names>P</given-names></name><name><surname>Zhou</surname><given-names>C</given-names></name><etal/></person-group><article-title>Effect of a deep-learning computer-aided detection system on adenoma detection during colonoscopy (CADe-DB trial): a double-blind randomised study</article-title><source>Lancet Gastroenterol Hepatol</source><year>2020</year><volume>5</volume><fpage>343</fpage><lpage>351</lpage><pub-id pub-id-type="pmid">31981517</pub-id></element-citation></ref><ref id="B45"><label>45</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>P</given-names></name><name><surname>Berzin</surname><given-names>TM</given-names></name><name><surname>Glissen Brown</surname><given-names>JR</given-names></name><name><surname>Bharadwaj</surname><given-names>S</given-names></name><name><surname>Becq</surname><given-names>A</given-names></name><name><surname>Xiao</surname><given-names>X</given-names></name><etal/></person-group><article-title>Real-time automatic detection system increases colonoscopic polyp and adenoma detection rates: a prospective randomised controlled study</article-title><source>Gut</source><year>2019</year><volume>68</volume><fpage>1813</fpage><lpage>1819</lpage><pub-id pub-id-type="pmid">30814121</pub-id></element-citation></ref><ref id="B46"><label>46</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>L</given-names></name><name><surname>Zhang</surname><given-names>J</given-names></name><name><surname>Zhou</surname><given-names>W</given-names></name><name><surname>An</surname><given-names>P</given-names></name><name><surname>Shen</surname><given-names>L</given-names></name><name><surname>Liu</surname><given-names>J</given-names></name><etal/></person-group><article-title>Randomised controlled trial of WISENSE, a real-time quality improving system for monitoring blind spots during esophagogastroduodenoscopy</article-title><source>Gut</source><year>2019</year><volume>68</volume><fpage>2161</fpage><lpage>2169</lpage><pub-id pub-id-type="pmid">30858305</pub-id></element-citation></ref><ref id="B47"><label>47</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Park</surname><given-names>SH</given-names></name></person-group><article-title>Regulatory approval versus clinical validation of artificial intelligence diagnostic tools</article-title><source>Radiology</source><year>2018</year><volume>288</volume><fpage>910</fpage><lpage>911</lpage><pub-id pub-id-type="pmid">30040041</pub-id></element-citation></ref><ref id="B48"><label>48</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eaneff</surname><given-names>S</given-names></name><name><surname>Obermeyer</surname><given-names>Z</given-names></name><name><surname>Butte</surname><given-names>AJ</given-names></name></person-group><article-title>The Case for Algorithmic Stewardship for Artificial Intelligence and Machine Learning Technologies</article-title><source>JAMA</source><year>2020</year><month>9</month><pub-id pub-id-type="doi">10.1001/jama.2020.9371</pub-id><comment>[Epub]</comment></element-citation></ref><ref id="B49"><label>49</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Park</surname><given-names>SH</given-names></name><name><surname>Do</surname><given-names>KH</given-names></name><name><surname>Kim</surname><given-names>S</given-names></name><name><surname>Park</surname><given-names>JH</given-names></name><name><surname>Lim</surname><given-names>YS</given-names></name></person-group><article-title>What should medical students know about artificial intelligence in medicine?</article-title><source>J Educ Eval Health Prof</source><year>2019</year><volume>16</volume><elocation-id>18</elocation-id><pub-id pub-id-type="pmid">31319450</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" orientation="portrait" position="float"><label>Fig. 1</label><caption><title>Dice similarity coefficient.</title></caption><graphic xlink:href="kjr-22-442-g001"/></fig><fig id="F2" orientation="portrait" position="float"><label>Fig. 2</label><caption><title>Diagnostic cross-table (also referred to as confusion matrix).</title><p>AI = artificial intelligence, FN = false negative, FP = false positive, TN = true negative, TP = true positive</p></caption><graphic xlink:href="kjr-22-442-g002"/></fig><fig id="F3" orientation="portrait" position="float"><label>Fig. 3</label><caption><title>Exemplary receiver operating characteristic curves that show the performance of four readers in interpreting breast ultrasonography assisted by a deep-learning algorithm.</title><p>Adapted from Choi et al. Korean J Radiol 2019;20:749-758, with permission from the Korean Society of Radiology [<xref rid="B4" ref-type="bibr">4</xref>]. AUC = area under the curve</p></caption><graphic xlink:href="kjr-22-442-g003"/></fig><fig id="F4" orientation="portrait" position="float"><label>Fig. 4</label><caption><title>Exemplary free-response receiver operating characteristic curves that show the performance of six methods of detecting polyps in colonoscopy videos.</title><p>The x-axis is the mean number of false positives per image frame. A curve closer to the left upper corner indicates a higher performance, for example, a higher performance of the red curve than the blue curve. Adapted from Tajbakhsh et al. Proceedings of IEEE 12th International Symposium on Biomedical Imaging. New York: IEEE; 2015, with permission from IEEE [<xref rid="B7" ref-type="bibr">7</xref>]. CNN = convolutional neural network</p></caption><graphic xlink:href="kjr-22-442-g004"/></fig><fig id="F5" orientation="portrait" position="float"><label>Fig. 5</label><caption><title>Typical data sets used for development and testing of an AI algorithm.</title><p>AI = artificial intelligence</p></caption><graphic xlink:href="kjr-22-442-g005"/></fig><table-wrap id="T1" orientation="portrait" position="float"><label>Table 1</label><caption><title>Examples of Limited Generalizability of the Performance of Artificial Intelligence Algorithms for Medical Diagnosis/Prediction</title></caption><alternatives><graphic xlink:href="kjr-22-442-i001"/><table frame="hsides" rules="rows"><col width="12%" span="1"/><col width="44%" span="1"/><col width="44%" span="1"/><thead><tr><th valign="middle" align="center" rowspan="1" colspan="1" style="background-color:rgb(200,227,231)">Author</th><th valign="middle" align="center" rowspan="1" colspan="1" style="background-color:rgb(200,227,231)">Algorithm</th><th valign="middle" align="center" rowspan="1" colspan="1" style="background-color:rgb(200,227,231)">Result</th></tr></thead><tbody><tr><td valign="middle" align="left" rowspan="1" colspan="1">Zech et al. [<xref rid="B12" ref-type="bibr">12</xref>]</td><td valign="middle" align="left" rowspan="1" colspan="1">CNN algorithm to detect pneumonia on chest radiographs</td><td valign="middle" align="left" rowspan="1" colspan="1">AUC of 0.931 in internal testing compared with 0.815 in external testing</td></tr><tr><td valign="middle" align="left" rowspan="1" colspan="1" style="background-color:rgb(215,234,236)">Ting et al. [<xref rid="B13" ref-type="bibr">13</xref>]</td><td valign="middle" align="left" rowspan="1" colspan="1" style="background-color:rgb(215,234,236)">CNN algorithm to detect referable diabetic retinopathy on retinal photographs</td><td valign="middle" align="left" rowspan="1" colspan="1" style="background-color:rgb(215,234,236)">AUC ranging from 0.889 to 0.983 when tested externally at 10 different hospitals</td></tr><tr><td valign="middle" align="left" rowspan="1" colspan="1">Ridley [<xref rid="B14" ref-type="bibr">14</xref>]</td><td valign="middle" align="left" rowspan="1" colspan="1">CNN algorithm to detect intracranial hemorrhage on noncontrast head computed tomography scans</td><td valign="middle" align="left" rowspan="1" colspan="1">Sensitivity, specificity, and AUC of 98%, 95%, and 0.993, respectively, when tested internally compared with 87.1%, 58.3%, and 0.834, respectively, when tested on a real-world data set</td></tr><tr><td valign="middle" align="left" rowspan="1" colspan="1" style="background-color:rgb(215,234,236)">Hwang et al. [<xref rid="B15" ref-type="bibr">15</xref>]</td><td valign="middle" align="left" rowspan="1" colspan="1" style="background-color:rgb(215,234,236)">CNN algorithm to distinguish normal chest radiographs from abnormal chest radiographs that contain any of the four types of pathologies including malignancy, tuberculosis, pneumonia, and pneumothorax</td><td valign="middle" align="left" rowspan="1" colspan="1" style="background-color:rgb(215,234,236)">When externally tested at five different hospitals with a single fixed threshold applied to the raw algorithm output, the specificity indicated a wide range from 56.6% to 100%, while the sensitivity was less variable ranging from 91.3% to 100%</td></tr><tr><td valign="middle" align="left" rowspan="1" colspan="1">Lee et al. [<xref rid="B16" ref-type="bibr">16</xref>]</td><td valign="middle" align="left" rowspan="1" colspan="1">CNN algorithm to categorize hepatic fibrosis (F0, F1, F2&#x02013;3, and F4 according to METAVIR scoring) on B-mode ultrasonography images</td><td valign="middle" align="left" rowspan="1" colspan="1">Accuracy of 83.5% in internal testing compared with 76.4% in external testing</td></tr></tbody></table></alternatives><table-wrap-foot><fn><p>AUC = area under the curve, CNN = convolutional neural network</p></fn></table-wrap-foot></table-wrap><table-wrap id="T2" orientation="portrait" position="float"><label>Table 2</label><caption><title>Examples of Randomized Controlled Trials that Compared Practice with and without Artificial Intelligence Algorithms</title></caption><alternatives><graphic xlink:href="kjr-22-442-i002"/><table frame="hsides" rules="rows"><col width="15%" span="1"/><col width="25%" span="1"/><col width="25%" span="1"/><col width="35%" span="1"/><thead><tr><th valign="middle" align="center" rowspan="1" colspan="1" style="background-color:rgb(200,227,231)">Author</th><th valign="middle" align="center" rowspan="1" colspan="1" style="background-color:rgb(200,227,231)">Algorithm</th><th valign="middle" align="center" rowspan="1" colspan="1" style="background-color:rgb(200,227,231)">Patient</th><th valign="middle" align="center" rowspan="1" colspan="1" style="background-color:rgb(200,227,231)">Primary Outcome</th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="1" colspan="1">Wijnberge et al. [<xref rid="B42" ref-type="bibr">42</xref>]</td><td valign="top" align="left" rowspan="1" colspan="1">Non-deep learning, machine learning algorithm that continuously analyzes arterial pressure waveform during surgery and warns if hypotensive event is expected within the next 15 minutes</td><td valign="top" align="left" rowspan="1" colspan="1">Adult patients (&#x02265; 18 years old) scheduled to undergo an elective noncardiac surgery under general anesthesia with need for continuous invasive blood pressure monitoring per arterial line</td><td valign="top" align="left" rowspan="1" colspan="1">Time-weighted average of hypotension during surgery defined as hypotension below a mean arterial pressure of 65 mm Hg (in millimeters of mercury) x time spent below a mean arterial pressure of 65 mm Hg (in minutes) divided by total duration of operation (in minutes)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" style="background-color:rgb(215,234,236)">INFANT Collaborative Group [<xref rid="B41" ref-type="bibr">41</xref>]</td><td valign="top" align="left" rowspan="1" colspan="1" style="background-color:rgb(215,234,236)">Non-deep learning, machine learning algorithm that continuously analyzes cardiotocographic data and delivers color-coded alerts to physicians when abnormalities are noted</td><td valign="top" align="left" rowspan="1" colspan="1" style="background-color:rgb(215,234,236)">Women in labor who require continuous electronic fetal heart rate monitoring</td><td valign="top" align="left" rowspan="1" colspan="1" style="background-color:rgb(215,234,236)">Rate of poor neonatal outcome (intrapartum stillbirth or early neonatal death excluding lethal congenital anomalies, or neonatal encephalopathy, admission to the neonatal unit within 24 h for &#x02265; 48 h with evidence of feeding difficulties, respiratory illness, or encephalopathy with evidence of compromise at birth), and developmental assessment at age 2 years in a subset of surviving children</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Repici et al. [<xref rid="B43" ref-type="bibr">43</xref>], Wang et al. [<xref rid="B44" ref-type="bibr">44</xref>], Wang et al. [<xref rid="B45" ref-type="bibr">45</xref>]</td><td valign="top" align="left" rowspan="1" colspan="1">CNN-based CADe algorithm that detects polyps on colonoscopy images</td><td valign="top" align="left" rowspan="1" colspan="1">Patients undergoing screening, surveillance, or diagnostic colonoscopy</td><td valign="top" align="left" rowspan="1" colspan="1">Adenoma detection rate (percentage of patients with at least one histologically proven adenoma or carcinoma)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1" style="background-color:rgb(215,234,236)">Wu et al. [<xref rid="B46" ref-type="bibr">46</xref>]</td><td valign="top" align="left" rowspan="1" colspan="1" style="background-color:rgb(215,234,236)">CNN-based algorithm that monitors occurrence of blind spots during esophagogastroduodenoscopy examination</td><td valign="top" align="left" rowspan="1" colspan="1" style="background-color:rgb(215,234,236)">Patients undergoing esophagogastroduodenoscopy</td><td valign="top" align="left" rowspan="1" colspan="1" style="background-color:rgb(215,234,236)">Rate of blind spots (number of unobserved sites/views from a total of 26 different sites/views in a patient as defined by the investigators) during endoscopic examination</td></tr></tbody></table></alternatives><table-wrap-foot><fn><p>CADe = computer-aided detection, CNN = convolutional neural network</p></fn></table-wrap-foot></table-wrap></floats-group></article>